srun: job 11448 queued and waiting for resources
srun: job 11448 has been allocated resources
+ ACTOR_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-13b-sft-model-ocra-500k/
+ CRITIC_MODEL_PATH=/home/zhaijidong/kinman/puzzle/puzzle/example/config/Llama2-350m-hf/
+ ACTOR_ZERO_STAGE=3
+ CRITIC_ZERO_STAGE=3
+ OUTPUT=
+ '[' '' == '' ']'
+ OUTPUT=./output_step3_llama
+ '[' 3 == '' ']'
+ '[' 3 == '' ']'
+ mkdir -p ./output_step3_llama
+ Num_Padding_at_Beginning=1
+ Actor_Lr=9.65e-6
+ Critic_Lr=5e-6
+ '[' -z ']'
+ '[' -z 11448 ']'
++ scontrol show JobId=11448
++ grep BatchHost
++ tr = ' '
++ awk '{print $2}'
+ ACTOR_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-13b-sft-model-ocra-500k/
+ CRITIC_MODEL_PATH=/home/zhaijidong/kinman/puzzle/puzzle/example/config/Llama2-350m-hf/
+ ACTOR_ZERO_STAGE=3
+ CRITIC_ZERO_STAGE=3
+ OUTPUT=
+ '[' '' == '' ']'
+ OUTPUT=./output_step3_llama
+ '[' 3 == '' ']'
+ '[' 3 == '' ']'
+ mkdir -p ./output_step3_llama
+ Num_Padding_at_Beginning=1
+ Actor_Lr=9.65e-6
+ Critic_Lr=5e-6
+ '[' -z ']'
+ '[' -z 11448 ']'
++ scontrol show JobId=11448
++ grep BatchHost
++ tr = ' '
++ awk '{print $2}'
+ export MASTER_ADDR=g4001
+ MASTER_ADDR=g4001
+ GPUS_PER_NODE=8
+ MASTER_PORT=6000
+ NNODES=2
+ NODE_RANK=1
+ DISTRIBUTED_ARGS='
    --nproc_per_node 8     --nnodes 2     --node_rank 1     --master_addr g4001     --master_port 6000
'
+ /home/zhaijidong/miniconda3/envs/ds/bin/torchrun --nproc_per_node 8 --nnodes 2 --node_rank 1 --master_addr g4001 --master_port 6000 main.py --data_path /home/zhaijidong/kinman/data/Dahoas/rm-static/ --data_split 2,4,4 --actor_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-13b-sft-model-ocra-500k/ --critic_model_name_or_path /home/zhaijidong/kinman/puzzle/puzzle/example/config/Llama2-350m-hf/ --num_padding_at_beginning 1 --per_device_generation_batch_size 16 --per_device_training_batch_size 16 --generation_batches 1 --ppo_epochs 1 --max_answer_seq_len 256 --max_prompt_seq_len 256 --actor_learning_rate 9.65e-6 --critic_learning_rate 5e-6 --actor_weight_decay 0.1 --critic_weight_decay 0.1 --num_train_epochs 1 --lr_scheduler_type cosine --gradient_accumulation_steps 1 --actor_gradient_checkpointing --critic_gradient_checkpointing --inference_tp_size 1 --actor_dropout 0.0 --num_warmup_steps 100 --deepspeed --seed 1234 --actor_zero_stage 3 --critic_zero_stage 3 --enable_hybrid_engine --offload --dat+ export MASTER_ADDR=g4001
+ MASTER_ADDR=g4001
+ GPUS_PER_NODE=8
+ MASTER_PORT=6000
+ NNODES=2
+ NODE_RANK=0
+ DISTRIBUTED_ARGS='
    --nproc_per_node 8     --nnodes 2     --node_rank 0     --master_addr g4001     --master_port 6000
'
+ /home/zhaijidong/miniconda3/envs/ds/bin/torchrun --nproc_per_node 8 --nnodes 2 --node_rank 0 --master_addr g4001 --master_port 6000 main.py --data_path /home/zhaijidong/kinman/data/Dahoas/rm-static/ --data_split 2,4,4 --actor_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-13b-sft-model-ocra-500k/ --critic_model_name_or_path /home/zhaijidong/kinman/puzzle/puzzle/example/config/Llama2-350m-hf/ --num_padding_at_beginning 1 --per_device_generation_batch_size 16 --per_device_training_batch_size 16 --generation_batches 1 --ppo_epochs 1 --max_answer_seq_len 256 --max_prompt_seq_len 256 --actor_learning_rate 9.65e-6 --critic_learning_rate 5e-6 --actor_weight_decay 0.1 --critic_weight_decay 0.1 --num_train_epochs 1 --lr_scheduler_type cosine --gradient_accumulation_steps 1 --actor_gradient_checkpointing --critic_gradient_checkpointing --inference_tp_size 1 --actor_dropout 0.0 --num_warmup_steps 100 --deepspeed --seed 1234 --actor_zero_stage 3 --critic_zero_stage 3 --enable_hybrid_engine --offload --data_output_path /home/zhaijidong/kinman/dstmp
a_output_path /home/zhaijidong/kinman/dstmp
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
[2024-04-28 09:37:58,917] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,917] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,942] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,945] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,964] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,968] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,989] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:58,995] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,414] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,426] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,427] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,430] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,430] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,430] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,444] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:37:59,447] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2024-04-28 09:38:05,494] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,506] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,517] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,526] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,529] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,530] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,536] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:05,547] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,504] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,516] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,546] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,548] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,554] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,558] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,569] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,574] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:38:06,575] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
************************[start] Initializing Actor Model [start] *************************
Setting model_config.attention_dropout to 0.0
[2024-04-28 09:38:20,881] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 363, num_elems = 13.02B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.4320404529571533 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
ninja: no work to do.
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.511631488800049 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.920480728149414 seconds
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.5212576389312744 secondsTime to load cpu_adam op: 3.5113120079040527 seconds

Loading extension module cpu_adam...
Time to load cpu_adam op: 3.566765546798706 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.5706028938293457 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.6766598224639893 seconds
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.628356456756592 seconds
Time to load cpu_adam op: 3.9897589683532715 seconds
Time to load cpu_adam op: 3.6825437545776367 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.5853469371795654 seconds
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.7020487785339355 seconds
Time to load cpu_adam op: 3.6971633434295654 seconds
Time to load cpu_adam op: 3.7158758640289307 seconds
Time to load cpu_adam op: 3.6039817333221436 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
[2024-04-28 09:38:28,510] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
[2024-04-28 09:38:28,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:38:28,542] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-28 09:38:28,542] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-28 09:38:28,559] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2024-04-28 09:38:28,559] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2024-04-28 09:38:28,559] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-28 09:38:28,559] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-28 09:38:28,740] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-28 09:38:28,741] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 1.07 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:28,741] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.96 GB, percent = 5.3%
[2024-04-28 09:38:28,743] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-28 09:38:28,743] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-28 09:38:28,899] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:38:28,900] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:28,900] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.96 GB, percent = 5.3%
Parameter Offload: Total persistent parameters: 414720 in 81 params
[2024-04-28 09:38:29,079] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:38:29,079] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:29,080] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.96 GB, percent = 5.3%
[2024-04-28 09:38:29,240] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-28 09:38:29,240] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:29,240] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.96 GB, percent = 5.3%
[2024-04-28 09:38:31,230] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-28 09:38:31,231] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:31,231] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 70.67 GB, percent = 7.0%
[2024-04-28 09:38:31,413] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-28 09:38:31,413] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:31,413] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 72.92 GB, percent = 7.2%
[2024-04-28 09:38:33,340] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-28 09:38:33,341] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:33,341] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 93.27 GB, percent = 9.3%
[2024-04-28 09:38:33,876] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-28 09:38:33,877] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:33,877] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 96.77 GB, percent = 9.6%
[2024-04-28 09:38:39,184] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-28 09:38:39,185] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.08 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:39,185] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 173.73 GB, percent = 17.2%
[2024-04-28 09:38:39,856] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-28 09:38:41,879] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-28 09:38:41,879] [INFO] [utils.py:804:see_memory_usage] MA 0.08 GB         Max_MA 0.69 GB         CA 1.3 GB         Max_CA 1 GB
[2024-04-28 09:38:41,879] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 178.28 GB, percent = 17.7%
[2024-04-28 09:38:41,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2024-04-28 09:38:41,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-28 09:38:41,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7fb51e59cb50>
[2024-04-28 09:38:41,880] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 09:38:41,880] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb4d13b2ee0>
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:38:41,881] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=True max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_actor_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:38:41,882] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:38:41,882] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "cpu"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": true,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_actor_tensorboard"
    }
}
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5354690551757812 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5278167724609375 seconds
Time to load transformer_inference op: 1.5278942584991455 seconds
Time to load transformer_inference op: 1.5406830310821533 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5319089889526367 seconds
Time to load transformer_inference op: 1.5305602550506592 seconds
Time to load transformer_inference op: 1.5145230293273926 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5350465774536133 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5374202728271484 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5383129119873047 seconds
Time to load transformer_inference op: 1.5396413803100586 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.5401089191436768 seconds
[2024-04-28 09:38:44,112] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 5120, 'intermediate_size': 13824, 'heads': 40, 'num_hidden_layers': -1, 'dtype': torch.float16, 'pre_layer_norm': True, 'norm_type': <NormType.RMSNorm: 3>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': 128, 'rotate_half': True, 'rotate_every_two': False, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GATED_SILU: 4>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 512, 'min_out_tokens': 512, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': True, 'transposed_mode': True, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1}
Time to load transformer_inference op: 1.6116340160369873 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 1.608088731765747 seconds
Time to load transformer_inference op: 1.6135401725769043 seconds
Time to load transformer_inference op: 1.6152901649475098 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3025481700897217 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.29675817489624023 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.31090712547302246 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.303680419921875 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3215630054473877 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3276529312133789 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3112301826477051 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3133261203765869 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.32778143882751465 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3379249572753906 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.33049511909484863 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3408033847808838 seconds
Time to load transformer_inference op: 0.3415844440460205 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3307490348815918 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.33178210258483887 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3313324451446533 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.29618167877197266 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.29968786239624023 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3169386386871338 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.32824277877807617 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3000671863555908 seconds
Time to load transformer_inference op: 0.3008852005004883 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3067615032196045 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.308276891708374 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3299999237060547 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3352019786834717 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3430917263031006 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.33139729499816895 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load transformer_inference op: 0.3326139450073242 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.33151960372924805 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3393223285675049 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.33570313453674316 seconds
******************[end] Initialized Actor Model [end] (duration: 32.03s)******************
*************************[start] Initializing Ref Model [start] **************************
[2024-04-28 09:38:50,356] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 726, num_elems = 26.03B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:38:50,362] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 09:38:50,399] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:38:50,401] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-28 09:38:50,588] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:38:50,589] [INFO] [utils.py:804:see_memory_usage] MA 2.08 GB         Max_MA 3.07 GB         CA 17.8 GB         Max_CA 18 GB
[2024-04-28 09:38:50,589] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 178.33 GB, percent = 17.7%
Parameter Offload: Total persistent parameters: 414720 in 81 params
[2024-04-28 09:38:50,762] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:38:50,762] [INFO] [utils.py:804:see_memory_usage] MA 2.08 GB         Max_MA 2.08 GB         CA 17.8 GB         Max_CA 18 GB
[2024-04-28 09:38:50,762] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 178.33 GB, percent = 17.7%
[2024-04-28 09:38:50,763] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:38:50,763] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:38:50,763] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:38:50,763] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:38:50,763] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb51d263f10>
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:38:50,764] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:38:50,765] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:38:50,765] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
*******************[end] Initialized Ref Model [end] (duration: 4.64s)********************
************************[start] Initializing Critic Model [start] ************************
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:38:51,071] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 872, num_elems = 26.34B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
>Creating model from_config took 0.3070988655090332 seconds
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.8918564319610596 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.889352798461914 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.933234214782715 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.9752981662750244 seconds
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.9600775241851807 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.8168489933013916 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.8392720222473145 seconds
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.9810473918914795 seconds
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.9295876026153564 seconds
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.9628593921661377 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.965911626815796 seconds
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.049153804779053 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.082700729370117 seconds
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.1848955154418945 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.252895355224609 seconds
No modifications detected for re-loaded extension module cpu_adam, skipping build step...
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.207212448120117 seconds
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
Adam Optimizer #1 is created with AVX512 arithmetic capability.
Config: alpha=0.000005, betas=(0.900000, 0.950000), weight_decay=0.000000, adam_w=1
[2024-04-28 09:38:58,003] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 09:38:58,010] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:38:58,011] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-28 09:38:58,011] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-28 09:38:58,014] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2024-04-28 09:38:58,014] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2024-04-28 09:38:58,014] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-28 09:38:58,014] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-28 09:38:58,203] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-28 09:38:58,204] [INFO] [utils.py:804:see_memory_usage] MA 2.12 GB         Max_MA 2.19 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:58,204] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 186.51 GB, percent = 18.5%
[2024-04-28 09:38:58,205] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-28 09:38:58,205] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-28 09:38:58,368] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:38:58,368] [INFO] [utils.py:804:see_memory_usage] MA 2.12 GB         Max_MA 2.12 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:58,368] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 186.51 GB, percent = 18.5%
Parameter Offload: Total persistent parameters: 17408 in 34 params
[2024-04-28 09:38:58,539] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:38:58,540] [INFO] [utils.py:804:see_memory_usage] MA 2.12 GB         Max_MA 2.12 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:58,540] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 186.51 GB, percent = 18.5%
[2024-04-28 09:38:58,702] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-28 09:38:58,702] [INFO] [utils.py:804:see_memory_usage] MA 2.12 GB         Max_MA 2.12 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:58,702] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 186.51 GB, percent = 18.5%
[2024-04-28 09:38:58,919] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-28 09:38:58,919] [INFO] [utils.py:804:see_memory_usage] MA 2.09 GB         Max_MA 2.12 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:58,920] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 187.52 GB, percent = 18.6%
[2024-04-28 09:38:59,082] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-28 09:38:59,082] [INFO] [utils.py:804:see_memory_usage] MA 2.09 GB         Max_MA 2.09 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:59,082] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 187.52 GB, percent = 18.6%
[2024-04-28 09:38:59,288] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-28 09:38:59,288] [INFO] [utils.py:804:see_memory_usage] MA 2.09 GB         Max_MA 2.09 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:59,289] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 187.59 GB, percent = 18.6%
[2024-04-28 09:38:59,473] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-28 09:38:59,473] [INFO] [utils.py:804:see_memory_usage] MA 2.09 GB         Max_MA 2.09 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:59,473] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 189.08 GB, percent = 18.8%
[2024-04-28 09:38:59,761] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-28 09:38:59,761] [INFO] [utils.py:804:see_memory_usage] MA 2.09 GB         Max_MA 2.09 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:38:59,761] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 189.29 GB, percent = 18.8%
[2024-04-28 09:38:59,762] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-28 09:39:00,066] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-28 09:39:00,066] [INFO] [utils.py:804:see_memory_usage] MA 2.09 GB         Max_MA 2.15 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:39:00,066] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 189.57 GB, percent = 18.8%
[2024-04-28 09:39:00,067] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2024-04-28 09:39:00,067] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-28 09:39:00,067] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7fb4d1411100>
[2024-04-28 09:39:00,067] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 09:39:00,067] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:39:00,067] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:39:00,067] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:39:00,067] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:39:00,067] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb4db508550>
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:39:00,068] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_critic_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:39:00,069] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:39:00,069] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "cpu"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": false,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_critic_tensorboard"
    }
}
******************[end] Initialized Critic Model [end] (duration: 9.30s)******************
************************[start] Initializing Reward Model [start] ************************
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:39:00,255] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1018, num_elems = 26.64B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
>Creating model from_config took 0.18734478950500488 seconds
[2024-04-28 09:39:00,257] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 09:39:00,262] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:39:00,263] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-28 09:39:00,441] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:39:00,441] [INFO] [utils.py:804:see_memory_usage] MA 2.13 GB         Max_MA 2.19 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:39:00,441] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 189.59 GB, percent = 18.8%
Parameter Offload: Total persistent parameters: 17408 in 34 params
[2024-04-28 09:39:00,635] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:39:00,636] [INFO] [utils.py:804:see_memory_usage] MA 2.13 GB         Max_MA 2.13 GB         CA 17.86 GB         Max_CA 18 GB
[2024-04-28 09:39:00,636] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 189.59 GB, percent = 18.8%
[2024-04-28 09:39:00,637] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb4d87bd9a0>
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:39:00,637] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:39:00,638] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:39:00,639] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "cpu"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
******************[end] Initialized Reward Model [end] (duration: 0.57s)******************
***** Running training *****
Beginning of Epoch 1/1, Total Generation Batches 120
------------------------------------------------------
Free memory : 49.925415 (GigaBytes)
Total memory: 79.151001 (GigaBytes)
Requested memory: 14.687500 (GigaBytes)
Setting maximum total tokens (input + output) to 512
WorkSpace: 0x7fa406000000
------------------------------------------------------
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch: 0 | Step: 0 | PPO Epoch: 1 | Actor Loss: -0.03328699246048927 | Critic Loss: 0.3293938636779785 | Unsupervised Loss: 0.0
End-to-End => Latency: 43.24s, TFLOPs: 24.58, Samples/sec: 5.92, Time/seq 0.17s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.33s, Per-token Latency 83.33 ms, TFLOPs: 9.92, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 21.91s, TFLOPs: 38.85
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.237548828125
-------------------------------------------------------------------------------------
|E2E latency=43.03s |Gather latency=1.19s (2.77%) |Generate time=16.44s (38.21%) |Training time=24.65s (57.29%) |Others=1.94 (4.50%)|CurSamplesPerSec=5.95 |AvgSamplesPerSec=5.95
Epoch: 0 | Step: 1 | PPO Epoch: 1 | Actor Loss: -0.03830355405807495 | Critic Loss: 0.29431337118148804 | Unsupervised Loss: 0.0
End-to-End => Latency: 38.53s, TFLOPs: 27.58, Samples/sec: 6.64, Time/seq 0.15s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.67s, Per-token Latency 84.64 ms, TFLOPs: 9.77, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 16.86s, TFLOPs: 50.47
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.1683349609375
-------------------------------------------------------------------------------------
|E2E latency=38.54s |Gather latency=1.42s (3.67%) |Generate time=16.42s (42.60%) |Training time=19.11s (49.60%) |Others=3.01 (7.80%)|CurSamplesPerSec=6.64 |AvgSamplesPerSec=6.28
Epoch: 0 | Step: 2 | PPO Epoch: 1 | Actor Loss: -0.07153873890638351 | Critic Loss: 0.3398897647857666 | Unsupervised Loss: 0.0
End-to-End => Latency: 37.42s, TFLOPs: 28.40, Samples/sec: 6.84, Time/seq 0.15s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.54s, Per-token Latency 84.12 ms, TFLOPs: 9.83, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.89s, TFLOPs: 53.57
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.1845703125
-------------------------------------------------------------------------------------
|E2E latency=37.43s |Gather latency=1.67s (4.47%) |Generate time=16.46s (43.98%) |Training time=18.33s (48.99%) |Others=2.63 (7.03%)|CurSamplesPerSec=6.84 |AvgSamplesPerSec=6.45
Epoch: 0 | Step: 3 | PPO Epoch: 1 | Actor Loss: -0.07270024716854095 | Critic Loss: 0.2976970672607422 | Unsupervised Loss: 0.0
End-to-End => Latency: 36.85s, TFLOPs: 28.84, Samples/sec: 6.95, Time/seq 0.14s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.20s, Per-token Latency 82.82 ms, TFLOPs: 9.98, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.65s, TFLOPs: 54.39
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.11395263671875
-------------------------------------------------------------------------------------
|E2E latency=36.86s |Gather latency=1.34s (3.63%) |Generate time=16.35s (44.36%) |Training time=18.14s (49.22%) |Others=2.37 (6.43%)|CurSamplesPerSec=6.95 |AvgSamplesPerSec=6.57
Epoch: 0 | Step: 4 | PPO Epoch: 1 | Actor Loss: 0.002149883657693863 | Critic Loss: 0.30362552404403687 | Unsupervised Loss: 0.0
End-to-End => Latency: 36.87s, TFLOPs: 28.82, Samples/sec: 6.94, Time/seq 0.14s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.18s, Per-token Latency 82.75 ms, TFLOPs: 9.99, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.69s, TFLOPs: 54.24
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.188720703125
-------------------------------------------------------------------------------------
|E2E latency=36.88s |Gather latency=1.33s (3.60%) |Generate time=16.33s (44.28%) |Training time=18.18s (49.30%) |Others=2.37 (6.42%)|CurSamplesPerSec=6.94 |AvgSamplesPerSec=6.64
Epoch: 0 | Step: 5 | PPO Epoch: 1 | Actor Loss: 0.029932837933301926 | Critic Loss: 0.3147033452987671 | Unsupervised Loss: 0.0
End-to-End => Latency: 37.21s, TFLOPs: 28.56, Samples/sec: 6.88, Time/seq 0.15s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.22s, Per-token Latency 82.88 ms, TFLOPs: 9.97, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.99s, TFLOPs: 53.22
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.168212890625
-------------------------------------------------------------------------------------
|E2E latency=37.21s |Gather latency=1.33s (3.57%) |Generate time=16.48s (44.29%) |Training time=18.36s (49.33%) |Others=2.37 (6.38%)|CurSamplesPerSec=6.88 |AvgSamplesPerSec=6.68
Epoch: 0 | Step: 6 | PPO Epoch: 1 | Actor Loss: -0.01972091943025589 | Critic Loss: 0.2817617356777191 | Unsupervised Loss: 0.0
End-to-End => Latency: 36.82s, TFLOPs: 28.87, Samples/sec: 6.95, Time/seq 0.14s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.26s, Per-token Latency 83.06 ms, TFLOPs: 9.95, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.55s, TFLOPs: 54.72
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.1798095703125
-------------------------------------------------------------------------------------
|E2E latency=36.82s |Gather latency=1.36s (3.70%) |Generate time=16.31s (44.31%) |Training time=18.13s (49.25%) |Others=2.37 (6.44%)|CurSamplesPerSec=6.95 |AvgSamplesPerSec=6.72
Epoch: 0 | Step: 7 | PPO Epoch: 1 | Actor Loss: -0.05335499346256256 | Critic Loss: 0.32385575771331787 | Unsupervised Loss: 0.0
End-to-End => Latency: 37.00s, TFLOPs: 28.72, Samples/sec: 6.92, Time/seq 0.14s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.23s, Per-token Latency 82.92 ms, TFLOPs: 9.97, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.77s, TFLOPs: 53.96
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.1298828125
-------------------------------------------------------------------------------------
|E2E latency=37.00s |Gather latency=1.36s (3.68%) |Generate time=16.35s (44.18%) |Training time=18.31s (49.47%) |Others=2.35 (6.35%)|CurSamplesPerSec=6.92 |AvgSamplesPerSec=6.74
Epoch: 0 | Step: 8 | PPO Epoch: 1 | Actor Loss: -0.13481324911117554 | Critic Loss: 0.3249841332435608 | Unsupervised Loss: 0.0
End-to-End => Latency: 37.23s, TFLOPs: 28.54, Samples/sec: 6.88, Time/seq 0.15s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.50s, Per-token Latency 83.98 ms, TFLOPs: 9.84, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.73s, TFLOPs: 54.10
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.1309814453125
-------------------------------------------------------------------------------------
|E2E latency=37.24s |Gather latency=1.32s (3.54%) |Generate time=16.51s (44.35%) |Training time=18.32s (49.19%) |Others=2.41 (6.46%)|CurSamplesPerSec=6.88 |AvgSamplesPerSec=6.76
[2024-04-28 09:45:18,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.65e-07, 9.65e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 09:45:18,336] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=16.903680522665308, CurrSamplesPerSec=16.769787508189733, MemAllocated=3.67GB, MaxMemAllocated=28.03GB
[2024-04-28 09:45:18,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[5.000000000000001e-07, 5.000000000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
Epoch: 0 | Step: 9 | PPO Epoch: 1 | Actor Loss: -0.029915548861026764 | Critic Loss: 0.3043055534362793 | Unsupervised Loss: 0.0
End-to-End => Latency: 37.09s, TFLOPs: 28.65, Samples/sec: 6.90, Time/seq 0.14s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.20s, Per-token Latency 82.81 ms, TFLOPs: 9.98, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.89s, TFLOPs: 53.54
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.117919921875
-------------------------------------------------------------------------------------
|E2E latency=37.10s |Gather latency=1.41s (3.79%) |Generate time=16.33s (44.03%) |Training time=18.36s (49.50%) |Others=2.40 (6.47%)|CurSamplesPerSec=6.90 |AvgSamplesPerSec=6.77
Epoch: 0 | Step: 10 | PPO Epoch: 1 | Actor Loss: -0.08671319484710693 | Critic Loss: 0.4044966995716095 | Unsupervised Loss: 0.0
End-to-End => Latency: 36.68s, TFLOPs: 28.97, Samples/sec: 6.98, Time/seq 0.14s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 21.31s, Per-token Latency 83.23 ms, TFLOPs: 9.93, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 15.38s, TFLOPs: 55.35
Actor Model Parameters => 13.016 B, Critic Model Parameters => 0.304 B
Average reward score: 0.15673828125
-------------------------------------------------------------------------------------
exit with early finished, for debug
