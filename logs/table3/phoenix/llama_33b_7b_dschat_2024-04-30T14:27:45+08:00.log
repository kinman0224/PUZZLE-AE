srun: job 11660 queued and waiting for resources
srun: job 11660 has been allocated resources
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,868] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,875] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-30 14:28:39,877] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2024-04-30 14:29:09,272] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,283] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,309] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,322] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,336] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,341] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,342] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,337] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,347] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,351] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,350] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,357] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,362] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,356] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,364] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,364] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-04-30 14:29:09,373] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,368] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,377] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,369] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,379] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,388] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,391] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,397] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,399] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,462] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,468] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,468] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,469] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,473] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,474] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,476] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-30 14:29:09,476] [INFO] [comm.py:637:init_distributed] cdb=None
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
************************[start] Initializing Actor Model [start] *************************
[2024-04-30 14:29:42,013] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 579, num_elems = 34.67B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-30 14:29:42,058] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 580, num_elems = 34.88B
[2024-04-30 14:29:42,178] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 581, num_elems = 35.10B
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...



Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.7051961421966553 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.7336418628692627 seconds
Time to load fused_adam op: 0.7139797210693359 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.7343301773071289 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.7343614101409912 seconds
Time to load fused_adam op: 0.7345058917999268 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.7344183921813965 secondsTime to load fused_adam op: 0.7196238040924072 seconds

Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.7408185005187988 secondsTime to load fused_adam op: 0.7408435344696045 seconds
Time to load fused_adam op: 0.7409999370574951 seconds

Time to load fused_adam op: 0.74080491065979 seconds
Time to load fused_adam op: 0.7403066158294678 secondsTime to load fused_adam op: 0.7404701709747314 seconds

Time to load fused_adam op: 0.7406480312347412 secondsTime to load fused_adam op: 0.7406635284423828 seconds

Time to load fused_adam op: 0.7477114200592041 secondsTime to load fused_adam op: 0.747138261795044 seconds

Time to load fused_adam op: 0.7471635341644287 seconds
Time to load fused_adam op: 0.7466657161712646 seconds
Time to load fused_adam op: 0.7471804618835449 secondsTime to load fused_adam op: 0.7467389106750488 seconds

Time to load fused_adam op: 0.7467861175537109 secondsTime to load fused_adam op: 0.7467751502990723 seconds

Time to load fused_adam op: 0.7527768611907959 seconds
Time to load fused_adam op: 0.7562735080718994 seconds
Time to load fused_adam op: 0.7564146518707275 seconds
Time to load fused_adam op: 0.7563652992248535 secondsTime to load fused_adam op: 0.7564983367919922 seconds

Time to load fused_adam op: 0.7566428184509277 seconds
Time to load fused_adam op: 0.7563862800598145 secondsTime to load fused_adam op: 0.756211519241333 seconds

[2024-04-30 14:29:44,266] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-30 14:29:44,381] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-30 14:29:44,383] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-30 14:29:44,383] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-30 14:29:44,415] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-04-30 14:29:44,415] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-04-30 14:29:44,415] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-30 14:29:44,415] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-30 14:29:44,624] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-30 14:29:44,626] [INFO] [utils.py:804:see_memory_usage] MA 0.1 GB         Max_MA 1.39 GB         CA 1.72 GB         Max_CA 2 GB
[2024-04-30 14:29:44,626] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 42.59 GB, percent = 4.2%
[2024-04-30 14:29:44,629] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-30 14:29:44,629] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-30 14:29:44,780] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-30 14:29:44,780] [INFO] [utils.py:804:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 1.72 GB         Max_CA 2 GB
[2024-04-30 14:29:44,780] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 42.6 GB, percent = 4.2%
Parameter Offload: Total persistent parameters: 858624 in 129 params
[2024-04-30 14:29:44,947] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-30 14:29:44,948] [INFO] [utils.py:804:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 1.72 GB         Max_CA 2 GB
[2024-04-30 14:29:44,948] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 42.6 GB, percent = 4.2%
[2024-04-30 14:29:45,089] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-30 14:29:45,090] [INFO] [utils.py:804:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 1.72 GB         Max_CA 2 GB
[2024-04-30 14:29:45,090] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 42.6 GB, percent = 4.2%
[2024-04-30 14:29:48,473] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 3
[2024-04-30 14:29:48,474] [INFO] [utils.py:804:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 1.72 GB         Max_CA 2 GB
[2024-04-30 14:29:48,474] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 75.24 GB, percent = 7.5%
[2024-04-30 14:29:48,622] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-30 14:29:48,622] [INFO] [utils.py:804:see_memory_usage] MA 0.1 GB         Max_MA 0.1 GB         CA 1.72 GB         Max_CA 2 GB
[2024-04-30 14:29:48,622] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 75.24 GB, percent = 7.5%
[2024-04-30 14:29:48,858] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-30 14:29:48,858] [INFO] [utils.py:804:see_memory_usage] MA 4.14 GB         Max_MA 5.7 GB         CA 9.19 GB         Max_CA 9 GB
[2024-04-30 14:29:48,859] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 75.24 GB, percent = 7.5%
[2024-04-30 14:29:49,000] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-30 14:29:49,001] [INFO] [utils.py:804:see_memory_usage] MA 4.14 GB         Max_MA 4.14 GB         CA 9.19 GB         Max_CA 9 GB
[2024-04-30 14:29:49,001] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 75.24 GB, percent = 7.5%
[2024-04-30 14:29:49,144] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-30 14:29:49,144] [INFO] [utils.py:804:see_memory_usage] MA 12.21 GB         Max_MA 15.94 GB         CA 20.39 GB         Max_CA 20 GB
[2024-04-30 14:29:49,144] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 75.24 GB, percent = 7.5%
[2024-04-30 14:29:49,145] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-30 14:29:52,297] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-30 14:29:52,298] [INFO] [utils.py:804:see_memory_usage] MA 14.23 GB         Max_MA 15.02 GB         CA 20.39 GB         Max_CA 20 GB
[2024-04-30 14:29:52,298] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 75.24 GB, percent = 7.5%
[2024-04-30 14:29:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-04-30 14:29:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-30 14:29:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f5d8fa7e970>
[2024-04-30 14:29:52,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-30 14:29:52,300] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5dd46d63d0>
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-30 14:29:52,300] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-30 14:29:52,301] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=True max_out_tokens=512 inference_tp_size=8 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_actor_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   train_batch_size ............. 128
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  4
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   world_size ................... 32
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-30 14:29:52,312] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-30 14:29:52,313] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-30 14:29:52,313] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-30 14:29:52,313] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-30 14:29:52,313] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 128,
    "train_micro_batch_size_per_gpu": 4,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": true,
        "max_out_tokens": 512,
        "inference_tp_size": 8,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_actor_tensorboard"
    }
}
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.901137113571167 seconds
Time to load transformer_inference op: 0.8585574626922607 seconds
Time to load transformer_inference op: 0.9015452861785889 seconds
Time to load transformer_inference op: 0.9021768569946289 seconds
Time to load transformer_inference op: 0.926826000213623 seconds
Time to load transformer_inference op: 0.9156076908111572 secondsTime to load transformer_inference op: 0.8548657894134521 seconds

Time to load transformer_inference op: 0.9010744094848633 secondsTime to load transformer_inference op: 0.90165114402771 seconds

Time to load transformer_inference op: 0.9017362594604492 seconds
Time to load transformer_inference op: 0.89961838722229 seconds
Time to load transformer_inference op: 0.901545524597168 seconds
Time to load transformer_inference op: 0.9060492515563965 secondsTime to load transformer_inference op: 0.9170517921447754 secondsTime to load transformer_inference op: 0.9064335823059082 seconds


Time to load transformer_inference op: 0.9005539417266846 seconds
Time to load transformer_inference op: 0.9250831604003906 seconds
Time to load transformer_inference op: 0.9042255878448486 seconds
Time to load transformer_inference op: 0.9211626052856445 seconds
Time to load transformer_inference op: 0.9142627716064453 seconds
Time to load transformer_inference op: 0.9234039783477783 secondsTime to load transformer_inference op: 0.9253365993499756 seconds
Time to load transformer_inference op: 0.9149222373962402 seconds

Time to load transformer_inference op: 0.8599224090576172 seconds
Time to load transformer_inference op: 0.9229669570922852 seconds
Time to load transformer_inference op: 0.9241633415222168 seconds
Time to load transformer_inference op: 0.8999447822570801 seconds
Time to load transformer_inference op: 0.9234697818756104 seconds
Time to load transformer_inference op: 0.8927104473114014 seconds
Time to load transformer_inference op: 0.9201171398162842 secondsTime to load transformer_inference op: 0.9278867244720459 seconds

Time to load transformer_inference op: 0.9007465839385986 seconds
[2024-04-30 14:29:53,690] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 6656, 'intermediate_size': 17920, 'heads': 64, 'num_hidden_layers': -1, 'dtype': torch.float16, 'pre_layer_norm': True, 'norm_type': <NormType.RMSNorm: 3>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 8, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': 104, 'rotate_half': True, 'rotate_every_two': False, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GATED_SILU: 4>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 512, 'min_out_tokens': 512, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': True, 'transposed_mode': True, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1}
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07787609100341797 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08053946495056152 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07819294929504395 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08345484733581543 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0822138786315918 seconds
Time to load transformer_inference op: 0.08971381187438965 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09430551528930664 seconds
Time to load transformer_inference op: 0.09350824356079102 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09577393531799316 seconds
Time to load transformer_inference op: 0.09899377822875977 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09634184837341309 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10060882568359375 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10542559623718262 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...No modifications detected for re-loaded extension module transformer_inference, skipping build step...

Loading extension module transformer_inference...Loading extension module transformer_inference...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load transformer_inference op: 0.09006524085998535 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08968257904052734 seconds
Time to load transformer_inference op: 0.09040999412536621 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09074974060058594 seconds
Time to load transformer_inference op: 0.08989477157592773 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10322690010070801 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09129834175109863 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09223484992980957 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0919034481048584 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07647275924682617 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09188532829284668 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07807588577270508 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08964419364929199 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09670233726501465 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.11049699783325195 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10942316055297852 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09860897064208984 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.1083676815032959 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10590434074401855 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08778882026672363 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09242796897888184 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0970618724822998 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.12328290939331055 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10268640518188477 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08726096153259277 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08773994445800781 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0922696590423584 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09385085105895996 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09280657768249512 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08882522583007812 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09878134727478027 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10382890701293945 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09243941307067871 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09925150871276855 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08688664436340332 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10805869102478027 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09369492530822754 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09046053886413574 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.13177943229675293 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07777929306030273 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08029508590698242 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08514070510864258 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load transformer_inference op: 0.10227489471435547 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.11036849021911621 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10219287872314453 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09838199615478516 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09566092491149902 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08406472206115723 seconds
******************[end] Initialized Actor Model [end] (duration: 32.07s)******************
*************************[start] Initializing Ref Model [start] **************************
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.1076347827911377 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10904049873352051 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.11246037483215332 seconds
[2024-04-30 14:30:11,682] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1160, num_elems = 69.76B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-30 14:30:11,727] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1161, num_elems = 69.98B
[2024-04-30 14:30:11,839] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1162, num_elems = 70.19B
[2024-04-30 14:30:11,909] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-30 14:30:11,983] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-30 14:30:11,988] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-30 14:30:12,204] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-30 14:30:12,204] [INFO] [utils.py:804:see_memory_usage] MA 14.42 GB         Max_MA 15.71 GB         CA 20.51 GB         Max_CA 21 GB
[2024-04-30 14:30:12,204] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.24 GB, percent = 8.6%
Parameter Offload: Total persistent parameters: 858624 in 129 params
[2024-04-30 14:30:12,394] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-30 14:30:12,394] [INFO] [utils.py:804:see_memory_usage] MA 14.42 GB         Max_MA 14.42 GB         CA 20.51 GB         Max_CA 21 GB
[2024-04-30 14:30:12,394] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.24 GB, percent = 8.6%
[2024-04-30 14:30:12,395] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5d8f5fe2b0>
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-30 14:30:12,396] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   train_batch_size ............. 128
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  4
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   world_size ................... 32
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-30 14:30:12,397] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-30 14:30:12,397] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 128,
    "train_micro_batch_size_per_gpu": 4,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "cpu"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
*******************[end] Initialized Ref Model [end] (duration: 17.98s)*******************
************************[start] Initializing Critic Model [start] ************************
[2024-04-30 14:30:13,837] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1308, num_elems = 70.49B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-30 14:30:13,841] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1309, num_elems = 70.51B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
>Creating model from_config took 1.4929804801940918 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Time to load fused_adam op: 0.0015747547149658203 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.0016574859619140625 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0019478797912597656 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0012786388397216797 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...No modifications detected for re-loaded extension module fused_adam, skipping build step...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.0023560523986816406 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Time to load fused_adam op: 0.0018434524536132812 secondsTime to load fused_adam op: 0.0018470287322998047 seconds

Loading extension module fused_adam...
Time to load fused_adam op: 0.001840829849243164 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0021021366119384766 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0018258094787597656 seconds
Time to load fused_adam op: 0.0014951229095458984 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.0012326240539550781 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.0012476444244384766 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.001283407211303711 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0012395381927490234 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...No modifications detected for re-loaded extension module fused_adam, skipping build step...

Loading extension module fused_adam...Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...

Loading extension module fused_adam...
Time to load fused_adam op: 0.0009496212005615234 seconds
Time to load fused_adam op: 0.001543283462524414 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0017046928405761719 seconds
Time to load fused_adam op: 0.0017788410186767578 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0016262531280517578 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.001590728759765625 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0027337074279785156 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Time to load fused_adam op: 0.0013053417205810547 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.0011141300201416016 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0012323856353759766 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Time to load fused_adam op: 0.003274679183959961 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0016016960144042969 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0034139156341552734 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.00212860107421875 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
[2024-04-30 14:30:14,025] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0044901371002197266 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.003295421600341797 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0014948844909667969 seconds
[2024-04-30 14:30:14,040] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-30 14:30:14,042] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-30 14:30:14,042] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-30 14:30:14,048] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-04-30 14:30:14,048] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-04-30 14:30:14,048] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-30 14:30:14,048] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-30 14:30:14,238] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-30 14:30:14,239] [INFO] [utils.py:804:see_memory_usage] MA 14.44 GB         Max_MA 14.51 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:14,239] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.25 GB, percent = 8.6%
[2024-04-30 14:30:14,240] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-30 14:30:14,240] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-30 14:30:14,401] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-30 14:30:14,402] [INFO] [utils.py:804:see_memory_usage] MA 14.44 GB         Max_MA 14.44 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:14,402] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.25 GB, percent = 8.6%
Parameter Offload: Total persistent parameters: 17408 in 34 params
[2024-04-30 14:30:14,570] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-30 14:30:14,571] [INFO] [utils.py:804:see_memory_usage] MA 14.44 GB         Max_MA 14.44 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:14,571] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.25 GB, percent = 8.6%
[2024-04-30 14:30:14,732] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-30 14:30:14,732] [INFO] [utils.py:804:see_memory_usage] MA 14.44 GB         Max_MA 14.44 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:14,732] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.25 GB, percent = 8.6%
[2024-04-30 14:30:14,919] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-30 14:30:14,920] [INFO] [utils.py:804:see_memory_usage] MA 14.42 GB         Max_MA 14.44 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:14,920] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.51 GB, percent = 8.6%
[2024-04-30 14:30:15,082] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-30 14:30:15,083] [INFO] [utils.py:804:see_memory_usage] MA 14.42 GB         Max_MA 14.42 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:15,083] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.51 GB, percent = 8.6%
[2024-04-30 14:30:15,243] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-30 14:30:15,244] [INFO] [utils.py:804:see_memory_usage] MA 14.46 GB         Max_MA 14.47 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:15,244] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.51 GB, percent = 8.6%
[2024-04-30 14:30:15,406] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-30 14:30:15,406] [INFO] [utils.py:804:see_memory_usage] MA 14.46 GB         Max_MA 14.46 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:15,406] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.51 GB, percent = 8.6%
[2024-04-30 14:30:15,567] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-30 14:30:15,567] [INFO] [utils.py:804:see_memory_usage] MA 14.53 GB         Max_MA 14.56 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:15,568] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.51 GB, percent = 8.6%
[2024-04-30 14:30:15,568] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-30 14:30:16,268] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-30 14:30:16,268] [INFO] [utils.py:804:see_memory_usage] MA 14.54 GB         Max_MA 14.61 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:16,268] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.51 GB, percent = 8.6%
[2024-04-30 14:30:16,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-04-30 14:30:16,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-30 14:30:16,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f5d8b618100>
[2024-04-30 14:30:16,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-30 14:30:16,269] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5d8b549bb0>
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-30 14:30:16,269] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_critic_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   train_batch_size ............. 128
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  4
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   world_size ................... 32
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-30 14:30:16,270] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-30 14:30:16,271] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 128,
    "train_micro_batch_size_per_gpu": 4,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": false,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_critic_tensorboard"
    }
}
******************[end] Initialized Critic Model [end] (duration: 3.87s)******************
************************[start] Initializing Reward Model [start] ************************
[2024-04-30 14:30:16,814] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1455, num_elems = 70.81B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-30 14:30:16,818] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1456, num_elems = 70.83B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
>Creating model from_config took 0.604177713394165 seconds
[2024-04-30 14:30:16,875] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-30 14:30:16,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-30 14:30:16,880] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-30 14:30:17,051] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-30 14:30:17,051] [INFO] [utils.py:804:see_memory_usage] MA 14.57 GB         Max_MA 14.64 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:17,051] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.53 GB, percent = 8.6%
Parameter Offload: Total persistent parameters: 17408 in 34 params
[2024-04-30 14:30:17,282] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-30 14:30:17,283] [INFO] [utils.py:804:see_memory_usage] MA 14.57 GB         Max_MA 14.57 GB         CA 20.54 GB         Max_CA 21 GB
[2024-04-30 14:30:17,283] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 86.53 GB, percent = 8.6%
[2024-04-30 14:30:17,283] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-30 14:30:17,283] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-30 14:30:17,283] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-30 14:30:17,283] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-30 14:30:17,283] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5d86659850>
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-30 14:30:17,284] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   train_batch_size ............. 128
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  4
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   world_size ................... 32
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-30 14:30:17,285] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-30 14:30:17,285] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 128,
    "train_micro_batch_size_per_gpu": 4,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
******************[end] Initialized Reward Model [end] (duration: 1.01s)******************
***** Running training *****
Beginning of Epoch 1/1, Total Generation Batches 239
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
------------------------------------------------------
Free memory : 36.132446 (GigaBytes)
Total memory: 79.151001 (GigaBytes)
Requested memory: 13.250000 (GigaBytes)
Setting maximum total tokens (input + output) to 512
WorkSpace: 0x7f4cee000000
------------------------------------------------------
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Generation time: 33.498762130737305, exp gen time: 40.37468767166138
[2024-04-30 14:31:11,463] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1
[2024-04-30 14:31:12,090] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1
Training time: 14.429395914077759
Epoch: 0 | Step: 0 | PPO Epoch: 1 | Actor Loss: 0.16221359372138977 | Critic Loss: 0.8715860843658447 | Unsupervised Loss: 0.0
End-to-End => Latency: 54.80s, TFLOPs: 12.96, Samples/sec: 2.34, Time/seq 0.43s, Batch Size: 128, Total Seq. Length: 512
Generation => Latency: 40.37s, Per-token Latency 157.71 ms, TFLOPs: 3.51, BW: 439.65 GB/sec, Answer Seq. Length: 256
Training   => Latency: 14.43s, TFLOPs: 39.39
Actor Model Parameters => 34.669 B, Critic Model Parameters => 0.304 B
Average reward score: 0.10693359375
-------------------------------------------------------------------------------------
|E2E latency=54.63s |Gather latency=3.06s (5.59%) |Generate time=30.44s (55.72%) |Training time=20.49s (37.51%) |Others=3.70 (6.77%)|CurSamplesPerSec=2.34 |AvgSamplesPerSec=2.34
Generation time: 24.322896718978882, exp gen time: 31.158742666244507
[2024-04-30 14:31:51,304] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
[2024-04-30 14:31:52,578] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
Training time: 9.340259790420532
Epoch: 0 | Step: 1 | PPO Epoch: 1 | Actor Loss: -0.25485777854919434 | Critic Loss: 0.802063524723053 | Unsupervised Loss: 0.0
End-to-End => Latency: 40.50s, TFLOPs: 17.54, Samples/sec: 3.16, Time/seq 0.32s, Batch Size: 128, Total Seq. Length: 512
Generation => Latency: 31.16s, Per-token Latency 121.71 ms, TFLOPs: 4.55, BW: 569.68 GB/sec, Answer Seq. Length: 256
Training   => Latency: 9.34s, TFLOPs: 60.85
Actor Model Parameters => 34.669 B, Critic Model Parameters => 0.304 B
Average reward score: 0.052978515625
-------------------------------------------------------------------------------------
|E2E latency=40.51s |Gather latency=2.91s (7.18%) |Generate time=21.41s (52.86%) |Training time=14.54s (35.90%) |Others=4.55 (11.24%)|CurSamplesPerSec=3.16 |AvgSamplesPerSec=2.69
Generation time: 23.48920774459839, exp gen time: 29.525729656219482
[2024-04-30 14:32:30,209] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
[2024-04-30 14:32:30,540] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
Training time: 8.407078266143799
Epoch: 0 | Step: 2 | PPO Epoch: 1 | Actor Loss: -0.06901620328426361 | Critic Loss: 0.7383142709732056 | Unsupervised Loss: 0.0
End-to-End => Latency: 37.93s, TFLOPs: 18.72, Samples/sec: 3.37, Time/seq 0.30s, Batch Size: 128, Total Seq. Length: 512
Generation => Latency: 29.53s, Per-token Latency 115.33 ms, TFLOPs: 4.80, BW: 601.19 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.41s, TFLOPs: 67.61
Actor Model Parameters => 34.669 B, Critic Model Parameters => 0.304 B
Average reward score: 0.0948486328125
-------------------------------------------------------------------------------------
|E2E latency=37.94s |Gather latency=2.89s (7.61%) |Generate time=20.60s (54.30%) |Training time=13.63s (35.93%) |Others=3.71 (9.77%)|CurSamplesPerSec=3.37 |AvgSamplesPerSec=2.89
Generation time: 24.58677577972412, exp gen time: 30.5484402179718
[2024-04-30 14:33:09,162] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
[2024-04-30 14:33:09,467] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
Training time: 8.371644735336304
Epoch: 0 | Step: 3 | PPO Epoch: 1 | Actor Loss: -0.025813238695263863 | Critic Loss: 0.7488788366317749 | Unsupervised Loss: 0.0
End-to-End => Latency: 38.92s, TFLOPs: 18.25, Samples/sec: 3.29, Time/seq 0.30s, Batch Size: 128, Total Seq. Length: 512
Generation => Latency: 30.55s, Per-token Latency 119.33 ms, TFLOPs: 4.64, BW: 581.07 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.37s, TFLOPs: 67.89
Actor Model Parameters => 34.669 B, Critic Model Parameters => 0.304 B
Average reward score: 0.1378173828125
-------------------------------------------------------------------------------------
|E2E latency=38.92s |Gather latency=2.93s (7.52%) |Generate time=21.66s (55.64%) |Training time=13.61s (34.97%) |Others=3.65 (9.38%)|CurSamplesPerSec=3.29 |AvgSamplesPerSec=2.98