srun: job 11451 queued and waiting for resources
srun: job 11451 has been allocated resources
+ ACTOR_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ CRITIC_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ ACTOR_ZERO_STAGE=3
+ CRITIC_ZERO_STAGE=3
+ OUTPUT=
+ '[' '' == '' ']'
+ OUTPUT=./output_step3_llama
+ '[' 3 == '' ']'
+ '[' 3 == '' ']'
+ mkdir -p ./output_step3_llama
+ ACTOR_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ CRITIC_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ ACTOR_ZERO_STAGE=3
+ CRITIC_ZERO_STAGE=3
+ OUTPUT=
+ '[' '' == '' ']'
+ OUTPUT=./output_step3_llama
+ '[' 3 == '' ']'
+ '[' 3 == '' ']'
+ mkdir -p ./output_step3_llama
+ Num_Padding_at_Beginning=1
+ Actor_Lr=9.65e-6
+ Critic_Lr=5e-6
+ '[' -z ']'
+ '[' -z 11451 ']'
++ scontrol show JobId=11451
++ grep BatchHost
++ tr = ' '
++ awk '{print $2}'
+ Num_Padding_at_Beginning=1
+ Actor_Lr=9.65e-6
+ Critic_Lr=5e-6
+ '[' -z ']'
+ '[' -z 11451 ']'
++ scontrol show JobId=11451
++ grep BatchHost
++ tr = ' '
++ awk '{print $2}'
+ export MASTER_ADDR=g4001
+ MASTER_ADDR=g4001
+ GPUS_PER_NODE=8
+ MASTER_PORT=6000
+ NNODES=2
+ NODE_RANK=0
+ DISTRIBUTED_ARGS='
    --nproc_per_node 8     --nnodes 2     --node_rank 0     --master_addr g4001     --master_port 6000
'
+ /home/zhaijidong/miniconda3/envs/ds/bin/torchrun --nproc_per_node 8 --nnodes 2 --node_rank 0 --master_addr g4001 --master_port 6000 main.py --data_path /home/zhaijidong/kinman/data/Dahoas/rm-static/ --data_split 2,4,4 --actor_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --critic_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --num_padding_at_beginning 1 --per_device_generation_batch_size 16 --per_device_training_batch_size 16 --generation_batches 1 --ppo_epochs 1 --max_answer_seq_len 256 --max_prompt_seq_len 256 --actor_learning_rate 9.65e-6 --critic_learning_rate 5e-6 --actor_weight_decay 0.1 --critic_weight_decay 0.1 --num_train_epochs 1 --lr_scheduler_type cosine --gradient_accumulation_steps 1 --actor_gradient_checkpointing --critic_gradient_checkpointing --offload_reference_model --actor_dropout 0.0 --num_warmup_steps 100 --deepspeed --seed 1234 --actor_zero_stage 3 --critic_zero_stage 3 --enable_hybrid_engine --data_output_p+ export MASTER_ADDR=g4001
+ MASTER_ADDR=g4001
+ GPUS_PER_NODE=8
+ MASTER_PORT=6000
+ NNODES=2
+ NODE_RANK=1
+ DISTRIBUTED_ARGS='
    --nproc_per_node 8     --nnodes 2     --node_rank 1     --master_addr g4001     --master_port 6000
'
+ /home/zhaijidong/miniconda3/envs/ds/bin/torchrun --nproc_per_node 8 --nnodes 2 --node_rank 1 --master_addr g4001 --master_port 6000 main.py --data_path /home/zhaijidong/kinman/data/Dahoas/rm-static/ --data_split 2,4,4 --actor_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --critic_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --num_padding_at_beginning 1 --per_device_generation_batch_size 16 --per_device_training_batch_size 16 --generation_batches 1 --ppo_epochs 1 --max_answer_seq_len 256 --max_prompt_seq_len 256 --actor_learning_rate 9.65e-6 --critic_learning_rate 5e-6 --actor_weight_decay 0.1 --critic_weight_decay 0.1 --num_train_epochs 1 --lr_scheduler_type cosine --gradient_accumulation_steps 1 --actor_gradient_checkpointing --critic_gradient_checkpointing --offload_reference_model --actor_dropout 0.0 --num_warmup_steps 100 --deepspeed --seed 1234 --actor_zero_stage 3 --critic_zero_stage 3 --enable_hybrid_engine --data_output_path /home/zhaijidong/kinman/dstmp
ath /home/zhaijidong/kinman/dstmp
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
[2024-04-28 10:00:40,671] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,672] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,677] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,685] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,685] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,686] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,686] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,698] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,883] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,884] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,884] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,884] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,884] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,885] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,886] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 10:00:40,886] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2024-04-28 10:00:47,071] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,401] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,403] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,408] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,411] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,413] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,416] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:47,423] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,047] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,055] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,056] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,061] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,065] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,082] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,091] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 10:00:48,091] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-04-28 10:00:48,099] [INFO] [comm.py:637:init_distributed] cdb=None
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
************************[start] Initializing Actor Model [start] *************************
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:00:59,480] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:00:59,505] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 292, num_elems = 6.87B
[2024-04-28 10:00:59,572] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 293, num_elems = 7.00B
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.4108595848083496 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.4070930480957031 seconds
Time to load fused_adam op: 0.40611886978149414 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.40584635734558105 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.40514373779296875 seconds
Time to load fused_adam op: 0.4058420658111572 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.4059317111968994 seconds
Time to load fused_adam op: 0.4057025909423828 seconds
Time to load fused_adam op: 0.40580105781555176 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.4056973457336426 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.4057424068450928 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.4058804512023926 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.40596699714660645 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.306704044342041 seconds
Time to load fused_adam op: 0.40593981742858887 seconds
[2024-04-28 10:01:00,831] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
Loading extension module fused_adam...
Time to load fused_adam op: 0.4060242176055908 seconds
[2024-04-28 10:01:00,875] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 10:01:00,876] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-28 10:01:00,876] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-28 10:01:00,891] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-04-28 10:01:00,891] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-04-28 10:01:00,891] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-28 10:01:00,891] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-28 10:01:01,049] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-28 10:01:01,050] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.86 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 10:01:01,050] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 32.0 GB, percent = 3.2%
[2024-04-28 10:01:01,052] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-28 10:01:01,052] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-28 10:01:01,186] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 10:01:01,186] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 10:01:01,186] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 32.0 GB, percent = 3.2%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2024-04-28 10:01:01,336] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 10:01:01,336] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 10:01:01,336] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 32.0 GB, percent = 3.2%
[2024-04-28 10:01:01,477] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-28 10:01:01,478] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 10:01:01,478] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 32.0 GB, percent = 3.2%
[2024-04-28 10:01:02,504] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-28 10:01:02,504] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 10:01:02,505] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 10:01:02,638] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-28 10:01:02,639] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 10:01:02,639] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 10:01:02,821] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-28 10:01:02,822] [INFO] [utils.py:804:see_memory_usage] MA 1.63 GB         Max_MA 2.42 GB         CA 4.43 GB         Max_CA 4 GB
[2024-04-28 10:01:02,822] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 10:01:02,956] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-28 10:01:02,957] [INFO] [utils.py:804:see_memory_usage] MA 1.63 GB         Max_MA 1.63 GB         CA 4.43 GB         Max_CA 4 GB
[2024-04-28 10:01:02,957] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 10:01:03,095] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-28 10:01:03,095] [INFO] [utils.py:804:see_memory_usage] MA 4.77 GB         Max_MA 6.34 GB         CA 9.14 GB         Max_CA 9 GB
[2024-04-28 10:01:03,095] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 10:01:03,096] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-28 10:01:03,749] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-28 10:01:03,750] [INFO] [utils.py:804:see_memory_usage] MA 5.55 GB         Max_MA 6.04 GB         CA 9.14 GB         Max_CA 9 GB
[2024-04-28 10:01:03,750] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 10:01:03,750] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-04-28 10:01:03,750] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-28 10:01:03,750] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f2181375430>
[2024-04-28 10:01:03,750] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 10:01:03,751] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 10:01:03,751] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 10:01:03,751] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 10:01:03,751] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2181312b50>
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=True max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 10:01:03,752] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_actor_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 10:01:03,753] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 10:01:03,753] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": true,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_actor_tensorboard"
    }
}
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5298089981079102 seconds
[2024-04-28 10:01:04,464] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 4096, 'intermediate_size': 11008, 'heads': 32, 'num_hidden_layers': -1, 'dtype': torch.float16, 'pre_layer_norm': True, 'norm_type': <NormType.RMSNorm: 3>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': 128, 'rotate_half': True, 'rotate_every_two': False, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GATED_SILU: 4>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 512, 'min_out_tokens': 512, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': True, 'transposed_mode': True, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1}
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3842594623565674 seconds
Time to load transformer_inference op: 0.38492846488952637 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39177632331848145 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3989064693450928 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3995184898376465 seconds
Time to load transformer_inference op: 0.3981633186340332 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3979156017303467 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39208316802978516 seconds
Time to load transformer_inference op: 0.3954482078552246 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3999662399291992 seconds
Time to load transformer_inference op: 0.4000115394592285 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3981621265411377 seconds
Time to load transformer_inference op: 0.4032442569732666 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3958144187927246 seconds
Time to load transformer_inference op: 0.39400386810302734 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0973200798034668 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09140801429748535 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08699488639831543 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0989828109741211 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0903322696685791 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09194588661193848 seconds
Time to load transformer_inference op: 0.09256911277770996 seconds
Time to load transformer_inference op: 0.08599233627319336 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09302759170532227 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0929725170135498 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0902550220489502 seconds
Time to load transformer_inference op: 0.09045624732971191 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09302711486816406 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09472870826721191 seconds
Time to load transformer_inference op: 0.08893251419067383 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09902262687683105 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09537935256958008 seconds
******************[end] Initialized Actor Model [end] (duration: 9.74s)*******************
*************************[start] Initializing Ref Model [start] **************************
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0904231071472168 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09028863906860352 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08954095840454102 seconds
Time to load transformer_inference op: 0.08649396896362305 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09261608123779297 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08978009223937988 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09811210632324219 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09287571907043457 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09365534782409668 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09084773063659668 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09300613403320312 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08719301223754883 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09445571899414062 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09427428245544434 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.10402774810791016 seconds
[2024-04-28 10:01:08,681] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 584, num_elems = 13.74B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:01:08,710] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 585, num_elems = 13.87B
[2024-04-28 10:01:08,771] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 586, num_elems = 14.00B
[2024-04-28 10:01:08,811] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 10:01:08,831] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 10:01:08,833] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-28 10:01:09,023] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 10:01:09,024] [INFO] [utils.py:804:see_memory_usage] MA 5.88 GB         Max_MA 6.67 GB         CA 9.2 GB         Max_CA 9 GB
[2024-04-28 10:01:09,024] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.54 GB, percent = 4.4%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2024-04-28 10:01:09,182] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 10:01:09,183] [INFO] [utils.py:804:see_memory_usage] MA 5.88 GB         Max_MA 5.88 GB         CA 9.2 GB         Max_CA 9 GB
[2024-04-28 10:01:09,183] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.54 GB, percent = 4.4%
[2024-04-28 10:01:09,184] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f21f58b71c0>
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 10:01:09,184] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 10:01:09,185] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 10:01:09,185] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "cpu"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
*******************[end] Initialized Ref Model [end] (duration: 4.15s)********************
************************[start] Initializing Critic Model [start] ************************
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:01:10,640] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 876, num_elems = 20.61B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:01:10,646] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 877, num_elems = 20.74B
>Creating model from_config took 1.659113883972168 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.002980470657348633 seconds
Time to load fused_adam op: 0.0030553340911865234 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.003019571304321289 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...


Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Time to load fused_adam op: 0.0033469200134277344 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...Loading extension module fused_adam...

No modifications detected for re-loaded extension module fused_adam, skipping build step...Loading extension module fused_adam...

No modifications detected for re-loaded extension module fused_adam, skipping build step...Loading extension module fused_adam...

Loading extension module fused_adam...No modifications detected for re-loaded extension module fused_adam, skipping build step...

Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.004235267639160156 secondsTime to load fused_adam op: 0.004252433776855469 seconds

Time to load fused_adam op: 0.004238128662109375 seconds
Time to load fused_adam op: 0.003945112228393555 seconds
Time to load fused_adam op: 0.004395961761474609 seconds
Time to load fused_adam op: 0.004500150680541992 seconds
Time to load fused_adam op: 0.004732608795166016 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0032024383544921875 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Time to load fused_adam op: 0.003192424774169922 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.003241300582885742 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0031633377075195312 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0032188892364501953 seconds
[2024-04-28 10:01:10,945] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 10:01:10,978] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 10:01:10,979] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-28 10:01:10,979] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-28 10:01:10,989] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-04-28 10:01:10,989] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-04-28 10:01:10,989] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-28 10:01:10,989] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-28 10:01:11,166] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-28 10:01:11,167] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 7.28 GB         CA 16.06 GB         Max_CA 16 GB
[2024-04-28 10:01:11,167] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.57 GB, percent = 4.4%
[2024-04-28 10:01:11,169] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-28 10:01:11,169] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-28 10:01:11,321] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 10:01:11,321] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 6.73 GB         CA 16.06 GB         Max_CA 16 GB
[2024-04-28 10:01:11,322] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.57 GB, percent = 4.4%
Parameter Offload: Total persistent parameters: 270336 in 66 params
[2024-04-28 10:01:11,491] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 10:01:11,492] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 6.73 GB         CA 16.06 GB         Max_CA 16 GB
[2024-04-28 10:01:11,492] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.57 GB, percent = 4.4%
[2024-04-28 10:01:11,646] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-28 10:01:11,647] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 6.73 GB         CA 16.06 GB         Max_CA 16 GB
[2024-04-28 10:01:11,647] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.57 GB, percent = 4.4%
[2024-04-28 10:01:12,506] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-28 10:01:12,507] [INFO] [utils.py:804:see_memory_usage] MA 5.96 GB         Max_MA 6.73 GB         CA 16.06 GB         Max_CA 16 GB
[2024-04-28 10:01:12,507] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.74 GB, percent = 5.2%
[2024-04-28 10:01:12,661] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-28 10:01:12,661] [INFO] [utils.py:804:see_memory_usage] MA 5.96 GB         Max_MA 5.96 GB         CA 16.06 GB         Max_CA 16 GB
[2024-04-28 10:01:12,661] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.74 GB, percent = 5.2%
[2024-04-28 10:01:12,850] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-28 10:01:12,851] [INFO] [utils.py:804:see_memory_usage] MA 7.5 GB         Max_MA 8.26 GB         CA 17.6 GB         Max_CA 18 GB
[2024-04-28 10:01:12,851] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.74 GB, percent = 5.2%
[2024-04-28 10:01:13,005] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-28 10:01:13,005] [INFO] [utils.py:804:see_memory_usage] MA 7.5 GB         Max_MA 7.5 GB         CA 17.6 GB         Max_CA 18 GB
[2024-04-28 10:01:13,006] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.74 GB, percent = 5.2%
[2024-04-28 10:01:13,154] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-28 10:01:13,154] [INFO] [utils.py:804:see_memory_usage] MA 10.57 GB         Max_MA 12.11 GB         CA 20.68 GB         Max_CA 21 GB
[2024-04-28 10:01:13,155] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.74 GB, percent = 5.2%
[2024-04-28 10:01:13,155] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-28 10:01:13,815] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-28 10:01:13,816] [INFO] [utils.py:804:see_memory_usage] MA 11.34 GB         Max_MA 11.83 GB         CA 20.68 GB         Max_CA 21 GB
[2024-04-28 10:01:13,816] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.74 GB, percent = 5.2%
[2024-04-28 10:01:13,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-04-28 10:01:13,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-28 10:01:13,816] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f21b2bf9790>
[2024-04-28 10:01:13,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 10:01:13,817] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f21af620bb0>
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 10:01:13,817] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_critic_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 10:01:13,818] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 10:01:13,819] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": false,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_critic_tensorboard"
    }
}
******************[end] Initialized Critic Model [end] (duration: 4.63s)******************
************************[start] Initializing Reward Model [start] ************************
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:01:15,126] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1167, num_elems = 27.35B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 10:01:15,135] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1168, num_elems = 27.48B
>Creating model from_config took 1.5117077827453613 seconds
[2024-04-28 10:01:15,331] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 10:01:15,355] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 10:01:15,356] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-28 10:01:15,534] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 10:01:15,535] [INFO] [utils.py:804:see_memory_usage] MA 12.2 GB         Max_MA 12.75 GB         CA 21.47 GB         Max_CA 21 GB
[2024-04-28 10:01:15,535] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.77 GB, percent = 5.2%
Parameter Offload: Total persistent parameters: 270336 in 66 params
[2024-04-28 10:01:15,735] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 10:01:15,735] [INFO] [utils.py:804:see_memory_usage] MA 12.2 GB         Max_MA 12.2 GB         CA 21.47 GB         Max_CA 21 GB
[2024-04-28 10:01:15,735] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.77 GB, percent = 5.2%
[2024-04-28 10:01:15,736] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 10:01:15,736] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 10:01:15,736] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 10:01:15,736] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 10:01:15,736] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f21af1e88b0>
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 10:01:15,737] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 10:01:15,738] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 10:01:15,738] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
******************[end] Initialized Reward Model [end] (duration: 1.92s)******************
***** Running training *****
Beginning of Epoch 1/1, Total Generation Batches 120
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
------------------------------------------------------
Free memory : 52.521118 (GigaBytes)
Total memory: 79.151001 (GigaBytes)
Requested memory: 9.750000 (GigaBytes)
Setting maximum total tokens (input + output) to 512
WorkSpace: 0x7f17ca000000
------------------------------------------------------
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Generation time: 11.74708104133606, exp gen time: 15.2899751663208
Training time: 10.777620792388916
Epoch: 0 | Step: 0 | PPO Epoch: 1 | Actor Loss: -0.04637744277715683 | Critic Loss: 0.34358492493629456 | Unsupervised Loss: 0.0
End-to-End => Latency: 26.07s, TFLOPs: 37.76, Samples/sec: 9.82, Time/seq 0.10s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 15.29s, Per-token Latency 59.73 ms, TFLOPs: 7.15, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 10.78s, TFLOPs: 81.18
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.1689453125
-------------------------------------------------------------------------------------
|E2E latency=25.90s |Gather latency=0.61s (2.35%) |Generate time=11.14s (43.00%) |Training time=9.99s (38.55%) |Others=4.78 (18.45%)|CurSamplesPerSec=9.88 |AvgSamplesPerSec=9.88
Generation time: 11.004632234573364, exp gen time: 15.107823133468628
Training time: 8.015572786331177
Epoch: 0 | Step: 1 | PPO Epoch: 1 | Actor Loss: -0.018040239810943604 | Critic Loss: 0.38082048296928406 | Unsupervised Loss: 0.0
End-to-End => Latency: 23.12s, TFLOPs: 42.57, Samples/sec: 11.07, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 15.11s, Per-token Latency 59.01 ms, TFLOPs: 7.24, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.02s, TFLOPs: 109.15
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.188232421875
-------------------------------------------------------------------------------------
|E2E latency=23.13s |Gather latency=0.94s (4.07%) |Generate time=10.06s (43.51%) |Training time=7.85s (33.94%) |Others=5.22 (22.55%)|CurSamplesPerSec=11.07 |AvgSamplesPerSec=10.44
Generation time: 11.123137474060059, exp gen time: 14.741869926452637
Training time: 8.042343378067017
Epoch: 0 | Step: 2 | PPO Epoch: 1 | Actor Loss: 0.057635851204395294 | Critic Loss: 0.35067513585090637 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.78s, TFLOPs: 43.20, Samples/sec: 11.24, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.74s, Per-token Latency 57.59 ms, TFLOPs: 7.42, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.04s, TFLOPs: 108.79
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.1173095703125
-------------------------------------------------------------------------------------
|E2E latency=22.79s |Gather latency=1.00s (4.41%) |Generate time=10.12s (44.40%) |Training time=7.25s (31.82%) |Others=5.42 (23.78%)|CurSamplesPerSec=11.23 |AvgSamplesPerSec=10.69
Generation time: 11.04694676399231, exp gen time: 14.713171243667603
Training time: 8.03382682800293
Epoch: 0 | Step: 3 | PPO Epoch: 1 | Actor Loss: -0.018955860286951065 | Critic Loss: 0.3613901138305664 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.75s, TFLOPs: 43.27, Samples/sec: 11.25, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.71s, Per-token Latency 57.47 ms, TFLOPs: 7.43, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.03s, TFLOPs: 108.90
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.1175537109375
-------------------------------------------------------------------------------------
|E2E latency=22.75s |Gather latency=0.95s (4.19%) |Generate time=10.09s (44.36%) |Training time=7.25s (31.88%) |Others=5.40 (23.76%)|CurSamplesPerSec=11.25 |AvgSamplesPerSec=10.83
Generation time: 10.955702066421509, exp gen time: 14.715122699737549
Training time: 8.090134859085083
Epoch: 0 | Step: 4 | PPO Epoch: 1 | Actor Loss: -0.05925237387418747 | Critic Loss: 0.37406009435653687 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.81s, TFLOPs: 43.16, Samples/sec: 11.23, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.72s, Per-token Latency 57.48 ms, TFLOPs: 7.43, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.09s, TFLOPs: 108.14
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.153076171875
-------------------------------------------------------------------------------------
|E2E latency=22.81s |Gather latency=0.95s (4.16%) |Generate time=10.01s (43.87%) |Training time=7.29s (31.96%) |Others=5.51 (24.17%)|CurSamplesPerSec=11.22 |AvgSamplesPerSec=10.90
Generation time: 11.02275562286377, exp gen time: 14.702405452728271
Training time: 8.052504301071167
Epoch: 0 | Step: 5 | PPO Epoch: 1 | Actor Loss: 0.04100264608860016 | Critic Loss: 0.3846338987350464 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.75s, TFLOPs: 43.26, Samples/sec: 11.25, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.70s, Per-token Latency 57.43 ms, TFLOPs: 7.44, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.05s, TFLOPs: 108.65
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.10394287109375
-------------------------------------------------------------------------------------
|E2E latency=22.76s |Gather latency=0.95s (4.19%) |Generate time=10.07s (44.23%) |Training time=7.27s (31.94%) |Others=5.42 (23.82%)|CurSamplesPerSec=11.25 |AvgSamplesPerSec=10.96
Generation time: 11.03421950340271, exp gen time: 14.879585266113281
Training time: 8.067032098770142
Epoch: 0 | Step: 6 | PPO Epoch: 1 | Actor Loss: -0.025508785620331764 | Critic Loss: 0.5158730745315552 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.95s, TFLOPs: 42.89, Samples/sec: 11.16, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.88s, Per-token Latency 58.12 ms, TFLOPs: 7.35, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.07s, TFLOPs: 108.45
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.165283203125
-------------------------------------------------------------------------------------
|E2E latency=22.95s |Gather latency=1.02s (4.43%) |Generate time=10.02s (43.65%) |Training time=7.45s (32.45%) |Others=5.48 (23.90%)|CurSamplesPerSec=11.15 |AvgSamplesPerSec=10.99
Generation time: 11.029321670532227, exp gen time: 14.660631656646729
Training time: 8.049788475036621
Epoch: 0 | Step: 7 | PPO Epoch: 1 | Actor Loss: -0.1402130126953125 | Critic Loss: 0.3923710584640503 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.71s, TFLOPs: 43.34, Samples/sec: 11.27, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.66s, Per-token Latency 57.27 ms, TFLOPs: 7.46, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.05s, TFLOPs: 108.69
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.0733642578125
-------------------------------------------------------------------------------------
|E2E latency=22.71s |Gather latency=1.00s (4.40%) |Generate time=10.03s (44.15%) |Training time=7.28s (32.04%) |Others=5.41 (23.80%)|CurSamplesPerSec=11.27 |AvgSamplesPerSec=11.02
Generation time: 10.96799635887146, exp gen time: 14.593302726745605
Training time: 8.074428796768188
Epoch: 0 | Step: 8 | PPO Epoch: 1 | Actor Loss: 0.00875104684382677 | Critic Loss: 0.35604292154312134 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.67s, TFLOPs: 43.42, Samples/sec: 11.29, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.59s, Per-token Latency 57.01 ms, TFLOPs: 7.49, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.07s, TFLOPs: 108.35
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.11590576171875
-------------------------------------------------------------------------------------
|E2E latency=22.67s |Gather latency=0.94s (4.16%) |Generate time=10.03s (44.22%) |Training time=7.26s (32.03%) |Others=5.39 (23.75%)|CurSamplesPerSec=11.29 |AvgSamplesPerSec=11.05
Generation time: 11.086004257202148, exp gen time: 14.713321924209595
[2024-04-28 10:05:03,204] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.65e-07, 9.65e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 10:05:03,204] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=62.92277498612099, CurrSamplesPerSec=62.61591388789849, MemAllocated=13.48GB, MaxMemAllocated=25.54GB
[2024-04-28 10:05:07,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[5.000000000000001e-07, 5.000000000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
Training time: 8.084545612335205
Epoch: 0 | Step: 9 | PPO Epoch: 1 | Actor Loss: -0.018987394869327545 | Critic Loss: 0.380961537361145 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.80s, TFLOPs: 43.17, Samples/sec: 11.23, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.71s, Per-token Latency 57.47 ms, TFLOPs: 7.43, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.08s, TFLOPs: 108.22
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.130126953125
-------------------------------------------------------------------------------------
|E2E latency=22.80s |Gather latency=1.01s (4.41%) |Generate time=10.08s (44.20%) |Training time=7.30s (32.02%) |Others=5.42 (23.77%)|CurSamplesPerSec=11.23 |AvgSamplesPerSec=11.07
Generation time: 11.01385760307312, exp gen time: 14.712779998779297
Training time: 8.08911681175232
Epoch: 0 | Step: 10 | PPO Epoch: 1 | Actor Loss: -0.02388773486018181 | Critic Loss: 0.3241499662399292 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.80s, TFLOPs: 43.17, Samples/sec: 11.23, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.71s, Per-token Latency 57.47 ms, TFLOPs: 7.43, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.09s, TFLOPs: 108.16
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.157958984375
-------------------------------------------------------------------------------------
exit with early finished, for debug
