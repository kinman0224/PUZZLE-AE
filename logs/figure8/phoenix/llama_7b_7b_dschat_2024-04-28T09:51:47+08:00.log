srun: job 11449 queued and waiting for resources
srun: job 11449 has been allocated resources
+ ACTOR_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ CRITIC_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ ACTOR_ZERO_STAGE=3
+ CRITIC_ZERO_STAGE=3
+ OUTPUT=
+ '[' '' == '' ']'
+ OUTPUT=./output_step3_llama
+ '[' 3 == '' ']'
+ '[' 3 == '' ']'
+ mkdir -p ./output_step3_llama
+ Num_Padding_at_Beginning=1
+ Actor_Lr=9.65e-6
+ Critic_Lr=5e-6
+ '[' -z ']'
+ '[' -z 11449 ']'
++ scontrol show JobId=11449
++ grep BatchHost
++ tr = ' '
++ awk '{print $2}'
+ ACTOR_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ CRITIC_MODEL_PATH=/home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/
+ ACTOR_ZERO_STAGE=3
+ CRITIC_ZERO_STAGE=3
+ OUTPUT=
+ '[' '' == '' ']'
+ OUTPUT=./output_step3_llama
+ '[' 3 == '' ']'
+ '[' 3 == '' ']'
+ mkdir -p ./output_step3_llama
+ Num_Padding_at_Beginning=1
+ Actor_Lr=9.65e-6
+ Critic_Lr=5e-6
+ '[' -z ']'
+ '[' -z 11449 ']'
++ scontrol show JobId=11449
++ grep BatchHost
++ tr = ' '
++ awk '{print $2}'
+ export MASTER_ADDR=g4001
+ MASTER_ADDR=g4001
+ GPUS_PER_NODE=8
+ MASTER_PORT=6000
+ NNODES=2
+ NODE_RANK=0
+ DISTRIBUTED_ARGS='
    --nproc_per_node 8     --nnodes 2     --node_rank 0     --master_addr g4001     --master_port 6000
'
+ /home/zhaijidong/miniconda3/envs/ds/bin/torchrun --nproc_per_node 8 --nnodes 2 --node_rank 0 --master_addr g4001 --master_port 6000 main.py --data_path /home/zhaijidong/kinman/data/Dahoas/rm-static/ --data_split 2,4,4 --actor_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --critic_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --num_padding_at_beginning 1 --per_device_generation_batch_size 16 --per_device_training_batch_size 16 --generation_batches 1 --ppo_epochs 1 --max_answer_seq_len 256 --max_prompt_seq_len 256 --actor_learning_rate 9.65e-6 --critic_learning_rate 5e-6 --actor_weight_decay 0.1 --critic_weight_decay 0.1 --num_train_epochs 1 --lr_scheduler_type cosine --gradient_accumulation_steps 1 --actor_gradient_checkpointing --critic_gradient_checkpointing --offload_reference_model --actor_dropout 0.0 --num_warmup_steps 100 --deepspeed --seed 1234 --actor_zero_stage 3 --critic_zero_stage 3 --enable_hybrid_engine --data_output_p+ export MASTER_ADDR=g4001
+ MASTER_ADDR=g4001
+ GPUS_PER_NODE=8
+ MASTER_PORT=6000
+ NNODES=2
+ NODE_RANK=1
+ DISTRIBUTED_ARGS='
    --nproc_per_node 8     --nnodes 2     --node_rank 1     --master_addr g4001     --master_port 6000
'
+ /home/zhaijidong/miniconda3/envs/ds/bin/torchrun --nproc_per_node 8 --nnodes 2 --node_rank 1 --master_addr g4001 --master_port 6000 main.py --data_path /home/zhaijidong/kinman/data/Dahoas/rm-static/ --data_split 2,4,4 --actor_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --critic_model_name_or_path /home/zhaijidong/kinman/hf-models/Llama-2-7b-sft-model-ocra-500k/ --num_padding_at_beginning 1 --per_device_generation_batch_size 16 --per_device_training_batch_size 16 --generation_batches 1 --ppo_epochs 1 --max_answer_seq_len 256 --max_prompt_seq_len 256 --actor_learning_rate 9.65e-6 --critic_learning_rate 5e-6 --actor_weight_decay 0.1 --critic_weight_decay 0.1 --num_train_epochs 1 --lr_scheduler_type cosine --gradient_accumulation_steps 1 --actor_gradient_checkpointing --critic_gradient_checkpointing --offload_reference_model --actor_dropout 0.0 --num_warmup_steps 100 --deepspeed --seed 1234 --actor_zero_stage 3 --critic_zero_stage 3 --enable_hybrid_engine --data_output_path /home/zhaijidong/kinman/dstmp
ath /home/zhaijidong/kinman/dstmp
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
[2024-04-28 09:51:54,264] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,265] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,266] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,269] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,270] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,270] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,270] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,273] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,355] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,356] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,358] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,359] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,361] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,363] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,367] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-28 09:51:54,399] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
[2024-04-28 09:52:01,526] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,526] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-04-28 09:52:01,542] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,549] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,552] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,555] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,557] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,564] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,566] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,574] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,610] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,618] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,621] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,633] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,650] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,672] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-28 09:52:01,685] [INFO] [comm.py:637:init_distributed] cdb=None
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
************************[start] Initializing Actor Model [start] *************************
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
Setting model_config.attention_dropout to 0.0
[2024-04-28 09:52:13,672] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:52:13,700] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 292, num_elems = 6.87B
[2024-04-28 09:52:13,762] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 293, num_elems = 7.00B
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.44362401962280273 seconds
Time to load fused_adam op: 0.49599170684814453 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.516547441482544 seconds
Time to load fused_adam op: 0.5150599479675293 seconds
Time to load fused_adam op: 0.511075496673584 seconds
Time to load fused_adam op: 0.522390604019165 seconds
Time to load fused_adam op: 0.5296823978424072 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.5062553882598877 seconds
Time to load fused_adam op: 0.5065197944641113 seconds
Time to load fused_adam op: 0.5062530040740967 seconds
[2024-04-28 09:52:15,086] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.5054469108581543 seconds
Time to load fused_adam op: 0.5052235126495361 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.5063230991363525 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.5059452056884766 seconds
Time to load fused_adam op: 0.5067956447601318 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.5060174465179443 seconds
[2024-04-28 09:52:15,165] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:52:15,166] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-28 09:52:15,166] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-28 09:52:15,176] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-04-28 09:52:15,176] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-04-28 09:52:15,176] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-28 09:52:15,176] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-28 09:52:15,337] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-28 09:52:15,338] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.86 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 09:52:15,338] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 31.99 GB, percent = 3.2%
[2024-04-28 09:52:15,340] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-28 09:52:15,340] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-28 09:52:15,477] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:52:15,478] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 09:52:15,478] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 31.99 GB, percent = 3.2%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2024-04-28 09:52:15,631] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:52:15,632] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 09:52:15,632] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 31.99 GB, percent = 3.2%
[2024-04-28 09:52:15,772] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-28 09:52:15,773] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 09:52:15,773] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 31.99 GB, percent = 3.2%
[2024-04-28 09:52:16,725] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-28 09:52:16,726] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 09:52:16,726] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.16 GB, percent = 4.0%
[2024-04-28 09:52:16,871] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-28 09:52:16,871] [INFO] [utils.py:804:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 1.29 GB         Max_CA 1 GB
[2024-04-28 09:52:16,872] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.16 GB, percent = 4.0%
[2024-04-28 09:52:17,050] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-28 09:52:17,050] [INFO] [utils.py:804:see_memory_usage] MA 1.63 GB         Max_MA 2.42 GB         CA 4.43 GB         Max_CA 4 GB
[2024-04-28 09:52:17,050] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.16 GB, percent = 4.0%
[2024-04-28 09:52:17,192] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-28 09:52:17,192] [INFO] [utils.py:804:see_memory_usage] MA 1.63 GB         Max_MA 1.63 GB         CA 4.43 GB         Max_CA 4 GB
[2024-04-28 09:52:17,192] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 09:52:17,338] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-28 09:52:17,338] [INFO] [utils.py:804:see_memory_usage] MA 4.77 GB         Max_MA 6.34 GB         CA 9.14 GB         Max_CA 9 GB
[2024-04-28 09:52:17,338] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 09:52:17,339] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-28 09:52:18,005] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-28 09:52:18,006] [INFO] [utils.py:804:see_memory_usage] MA 5.55 GB         Max_MA 6.04 GB         CA 9.14 GB         Max_CA 9 GB
[2024-04-28 09:52:18,006] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 40.17 GB, percent = 4.0%
[2024-04-28 09:52:18,006] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-04-28 09:52:18,006] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-28 09:52:18,006] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f1e69f34250>
[2024-04-28 09:52:18,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 09:52:18,007] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:52:18,007] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:52:18,007] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:52:18,007] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:52:18,007] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1e69ed9460>
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=True max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_actor_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:52:18,008] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:52:18,009] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:52:18,009] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": true,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_actor_tensorboard"
    }
}
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/zhaijidong/.cache/torch_extensions/py39_cu117/transformer_inference/build.ninja...
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.5568768978118896 seconds
[2024-04-28 09:52:18,735] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 4096, 'intermediate_size': 11008, 'heads': 32, 'num_hidden_layers': -1, 'dtype': torch.float16, 'pre_layer_norm': True, 'norm_type': <NormType.RMSNorm: 3>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': 128, 'rotate_half': True, 'rotate_every_two': False, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GATED_SILU: 4>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 512, 'min_out_tokens': 512, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': True, 'transposed_mode': True, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1}
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.3954751491546631 seconds
Time to load transformer_inference op: 0.3984262943267822 seconds
Time to load transformer_inference op: 0.39433789253234863 seconds
Time to load transformer_inference op: 0.3964059352874756 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39045095443725586 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39789676666259766 seconds
Time to load transformer_inference op: 0.39745020866394043 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39852428436279297 seconds
Time to load transformer_inference op: 0.40058159828186035 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39629340171813965 seconds
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.38795948028564453 seconds
Time to load transformer_inference op: 0.39609622955322266 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.39724254608154297 seconds
Time to load transformer_inference op: 0.3969249725341797 seconds
Time to load transformer_inference op: 0.39719152450561523 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07777166366577148 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0698399543762207 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07902097702026367 seconds
Time to load transformer_inference op: 0.08490133285522461 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08710503578186035 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08157038688659668 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09116244316101074 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0914156436920166 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09300947189331055 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08960819244384766 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load transformer_inference op: 0.08776664733886719 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load transformer_inference op: 0.08611845970153809 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09035801887512207 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08169150352478027 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09522557258605957 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0958547592163086 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.07792162895202637 seconds
******************[end] Initialized Actor Model [end] (duration: 9.18s)*******************
*************************[start] Initializing Ref Model [start] **************************
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08869600296020508 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08626937866210938 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.0855109691619873 seconds
Time to load transformer_inference op: 0.08315563201904297 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09191131591796875 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08368992805480957 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08815479278564453 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09283137321472168 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08560681343078613 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load transformer_inference op: 0.08217978477478027 seconds
Time to load transformer_inference op: 0.08956599235534668 seconds
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09201669692993164 seconds
Time to load transformer_inference op: 0.0882883071899414 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.08664059638977051 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module transformer_inference, skipping build step...
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.09356808662414551 seconds
[2024-04-28 09:52:22,978] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 584, num_elems = 13.74B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:52:23,006] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 585, num_elems = 13.87B
[2024-04-28 09:52:23,067] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 586, num_elems = 14.00B
[2024-04-28 09:52:23,103] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 09:52:23,127] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:52:23,129] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-28 09:52:23,309] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:52:23,310] [INFO] [utils.py:804:see_memory_usage] MA 5.88 GB         Max_MA 6.67 GB         CA 9.2 GB         Max_CA 9 GB
[2024-04-28 09:52:23,310] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.53 GB, percent = 4.4%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2024-04-28 09:52:23,473] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:52:23,474] [INFO] [utils.py:804:see_memory_usage] MA 5.88 GB         Max_MA 5.88 GB         CA 9.2 GB         Max_CA 9 GB
[2024-04-28 09:52:23,474] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.53 GB, percent = 4.4%
[2024-04-28 09:52:23,475] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1e6a0827f0>
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:52:23,475] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:52:23,476] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:52:23,476] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "cpu"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
*******************[end] Initialized Ref Model [end] (duration: 4.25s)********************
************************[start] Initializing Critic Model [start] ************************
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:52:24,896] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 876, num_elems = 20.61B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:52:24,902] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 877, num_elems = 20.74B
>Creating model from_config took 1.6237711906433105 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0035614967346191406 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Time to load fused_adam op: 0.003381967544555664 seconds
Time to load fused_adam op: 0.004006147384643555 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...

Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...No modifications detected for re-loaded extension module fused_adam, skipping build step...

Loading extension module fused_adam...Loading extension module fused_adam...

Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0029277801513671875 seconds
Time to load fused_adam op: 0.003095865249633789 seconds
Time to load fused_adam op: 0.00325775146484375 seconds
[2024-04-28 09:52:25,187] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
Time to load fused_adam op: 0.0027654170989990234 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.003421783447265625 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Time to load fused_adam op: 0.0032510757446289062 seconds
Time to load fused_adam op: 0.0035049915313720703 seconds
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.003090381622314453 seconds
Time to load fused_adam op: 0.003932476043701172 seconds
Time to load fused_adam op: 0.0033257007598876953 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
Time to load fused_adam op: 0.0033915042877197266 seconds
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0034897327423095703 seconds
Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /home/zhaijidong/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module fused_adam, skipping build step...
Loading extension module fused_adam...
Time to load fused_adam op: 0.0017542839050292969 seconds
[2024-04-28 09:52:25,226] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:52:25,227] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-28 09:52:25,227] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-28 09:52:25,235] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-04-28 09:52:25,236] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-04-28 09:52:25,236] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-04-28 09:52:25,236] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2024-04-28 09:52:25,413] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning
[2024-04-28 09:52:25,413] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 7.28 GB         CA 15.91 GB         Max_CA 16 GB
[2024-04-28 09:52:25,413] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.56 GB, percent = 4.4%
[2024-04-28 09:52:25,415] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-04-28 09:52:25,415] [INFO] [stage3.py:127:__init__] Prefetch bucket size 30000000
[2024-04-28 09:52:25,572] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:52:25,572] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 6.73 GB         CA 15.91 GB         Max_CA 16 GB
[2024-04-28 09:52:25,572] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.56 GB, percent = 4.4%
Parameter Offload: Total persistent parameters: 270336 in 66 params
[2024-04-28 09:52:25,742] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:52:25,742] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 6.73 GB         CA 15.91 GB         Max_CA 16 GB
[2024-04-28 09:52:25,742] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.56 GB, percent = 4.4%
[2024-04-28 09:52:25,898] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions
[2024-04-28 09:52:25,899] [INFO] [utils.py:804:see_memory_usage] MA 6.73 GB         Max_MA 6.73 GB         CA 15.91 GB         Max_CA 16 GB
[2024-04-28 09:52:25,899] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 44.56 GB, percent = 4.4%
[2024-04-28 09:52:26,804] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2
[2024-04-28 09:52:26,805] [INFO] [utils.py:804:see_memory_usage] MA 5.96 GB         Max_MA 6.73 GB         CA 15.91 GB         Max_CA 16 GB
[2024-04-28 09:52:26,805] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.73 GB, percent = 5.2%
[2024-04-28 09:52:26,961] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions
[2024-04-28 09:52:26,962] [INFO] [utils.py:804:see_memory_usage] MA 5.96 GB         Max_MA 5.96 GB         CA 15.91 GB         Max_CA 16 GB
[2024-04-28 09:52:26,962] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.73 GB, percent = 5.2%
[2024-04-28 09:52:27,154] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions
[2024-04-28 09:52:27,154] [INFO] [utils.py:804:see_memory_usage] MA 7.5 GB         Max_MA 8.26 GB         CA 17.45 GB         Max_CA 17 GB
[2024-04-28 09:52:27,155] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.73 GB, percent = 5.2%
[2024-04-28 09:52:27,311] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states
[2024-04-28 09:52:27,312] [INFO] [utils.py:804:see_memory_usage] MA 7.5 GB         Max_MA 7.5 GB         CA 17.45 GB         Max_CA 17 GB
[2024-04-28 09:52:27,312] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.73 GB, percent = 5.2%
[2024-04-28 09:52:27,472] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states
[2024-04-28 09:52:27,472] [INFO] [utils.py:804:see_memory_usage] MA 10.57 GB         Max_MA 12.11 GB         CA 20.53 GB         Max_CA 21 GB
[2024-04-28 09:52:27,472] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.73 GB, percent = 5.2%
[2024-04-28 09:52:27,473] [INFO] [stage3.py:459:_setup_for_real_optimizer] optimizer state initialized
[2024-04-28 09:52:28,134] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer
[2024-04-28 09:52:28,135] [INFO] [utils.py:804:see_memory_usage] MA 11.34 GB         Max_MA 11.83 GB         CA 20.53 GB         Max_CA 21 GB
[2024-04-28 09:52:28,135] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.73 GB, percent = 5.2%
[2024-04-28 09:52:28,135] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-04-28 09:52:28,135] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-28 09:52:28,135] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f1e69f2ec40>
[2024-04-28 09:52:28,135] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 09:52:28,136] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:52:28,136] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1e69b51460>
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=True pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step3_tensorboard/ds_tensorboard_logs/', job_name='step3_critic_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:52:28,137] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:52:28,138] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:52:28,138] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "stage3_max_live_parameters": 3.000000e+07,
        "stage3_prefetch_bucket_size": 3.000000e+07,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true,
        "loss_scale_window": 100
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false,
    "hybrid_engine": {
        "enabled": false,
        "max_out_tokens": 512,
        "inference_tp_size": 1,
        "release_inference_cache": true,
        "pin_parameters": true,
        "tp_gather_partition_size": 8
    },
    "tensorboard": {
        "enabled": false,
        "output_path": "step3_tensorboard/ds_tensorboard_logs/",
        "job_name": "step3_critic_tensorboard"
    }
}
******************[end] Initialized Critic Model [end] (duration: 4.66s)******************
************************[start] Initializing Reward Model [start] ************************
[2024-04-28 09:52:29,439] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1167, num_elems = 27.35B
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32008. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[2024-04-28 09:52:29,445] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1168, num_elems = 27.48B
>Creating model from_config took 1.5055820941925049 seconds
[2024-04-28 09:52:29,644] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.4+18c8aa06, git-hash=18c8aa06, git-branch=fix_tp
[2024-04-28 09:52:29,668] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-28 09:52:29,670] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-04-28 09:52:29,835] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-04-28 09:52:29,835] [INFO] [utils.py:804:see_memory_usage] MA 12.19 GB         Max_MA 12.74 GB         CA 21.57 GB         Max_CA 22 GB
[2024-04-28 09:52:29,836] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.76 GB, percent = 5.2%
Parameter Offload: Total persistent parameters: 270336 in 66 params
[2024-04-28 09:52:30,044] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-04-28 09:52:30,045] [INFO] [utils.py:804:see_memory_usage] MA 12.19 GB         Max_MA 12.19 GB         CA 21.57 GB         Max_CA 22 GB
[2024-04-28 09:52:30,045] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 52.76 GB, percent = 5.2%
[2024-04-28 09:52:30,046] [INFO] [config.py:967:print] DeepSpeedEngine configuration:
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   amp_enabled .................. False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   amp_params ................... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   bfloat16_enabled ............. False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1e25bb8c40>
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   communication_data_type ...... None
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   dataloader_drop_last ......... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   disable_allgather ............ False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   dump_state ................... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   elasticity_enabled ........... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   fp16_auto_cast ............... False
[2024-04-28 09:52:30,046] [INFO] [config.py:971:print]   fp16_enabled ................. True
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   global_rank .................. 0
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   grad_accum_dtype ............. None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 1
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   load_universal_checkpoint .... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   loss_scale ................... 0
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   memory_breakdown ............. False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   mics_shard_size .............. -1
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   optimizer_name ............... None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   optimizer_params ............. None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   pld_enabled .................. False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   pld_params ................... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   prescale_gradients ........... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   scheduler_name ............... None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   scheduler_params ............. None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   sparse_attention ............. None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   steps_per_print .............. 10
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   train_batch_size ............. 256
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  16
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   use_node_local_storage ....... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   weight_quantization_config ... None
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   world_size ................... 16
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   zero_enabled ................. True
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-28 09:52:30,047] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3
[2024-04-28 09:52:30,047] [INFO] [config.py:957:print_user_config]   json = {
    "train_batch_size": 256,
    "train_micro_batch_size_per_gpu": 16,
    "steps_per_print": 10,
    "zero_optimization": {
        "stage": 3,
        "stage3_param_persistence_threshold": 1.000000e+04,
        "offload_param": {
            "device": "none"
        },
        "contiguous_gradients": false,
        "memory_efficient_linear": false
    },
    "fp16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "prescale_gradients": false,
    "wall_clock_breakdown": false
}
******************[end] Initialized Reward Model [end] (duration: 1.91s)******************
***** Running training *****
Beginning of Epoch 1/1, Total Generation Batches 120
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )
  warnings.warn(
------------------------------------------------------
Free memory : 52.515259 (GigaBytes)
Total memory: 79.151001 (GigaBytes)
Requested memory: 9.750000 (GigaBytes)
Setting maximum total tokens (input + output) to 512
WorkSpace: 0x7f1440000000
------------------------------------------------------
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/home/zhaijidong/miniconda3/envs/ds/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch: 0 | Step: 0 | PPO Epoch: 1 | Actor Loss: -0.04637744277715683 | Critic Loss: 0.34358492493629456 | Unsupervised Loss: 0.0
End-to-End => Latency: 26.20s, TFLOPs: 37.56, Samples/sec: 9.77, Time/seq 0.10s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 15.31s, Per-token Latency 59.81 ms, TFLOPs: 7.14, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 10.89s, TFLOPs: 80.34
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.1689453125
-------------------------------------------------------------------------------------
|E2E latency=26.03s |Gather latency=0.64s (2.47%) |Generate time=11.22s (43.13%) |Training time=10.01s (38.45%) |Others=4.79 (18.42%)|CurSamplesPerSec=9.84 |AvgSamplesPerSec=9.84
Epoch: 0 | Step: 1 | PPO Epoch: 1 | Actor Loss: -0.018040239810943604 | Critic Loss: 0.38082048296928406 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.43s, TFLOPs: 43.89, Samples/sec: 11.41, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.42s, Per-token Latency 56.31 ms, TFLOPs: 7.59, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.01s, TFLOPs: 109.20
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.188232421875
-------------------------------------------------------------------------------------
|E2E latency=22.43s |Gather latency=0.95s (4.24%) |Generate time=9.99s (44.52%) |Training time=7.29s (32.49%) |Others=5.16 (22.99%)|CurSamplesPerSec=11.41 |AvgSamplesPerSec=10.57
Epoch: 0 | Step: 2 | PPO Epoch: 1 | Actor Loss: 0.057635851204395294 | Critic Loss: 0.35067513585090637 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.76s, TFLOPs: 43.24, Samples/sec: 11.25, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.72s, Per-token Latency 57.51 ms, TFLOPs: 7.43, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.04s, TFLOPs: 108.83
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.1173095703125
-------------------------------------------------------------------------------------
|E2E latency=22.77s |Gather latency=1.03s (4.51%) |Generate time=10.15s (44.59%) |Training time=7.19s (31.57%) |Others=5.43 (23.84%)|CurSamplesPerSec=11.25 |AvgSamplesPerSec=10.78
Epoch: 0 | Step: 3 | PPO Epoch: 1 | Actor Loss: -0.018955860286951065 | Critic Loss: 0.3613901138305664 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.81s, TFLOPs: 43.16, Samples/sec: 11.23, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.76s, Per-token Latency 57.64 ms, TFLOPs: 7.41, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.05s, TFLOPs: 108.67
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.1175537109375
-------------------------------------------------------------------------------------
|E2E latency=22.81s |Gather latency=0.95s (4.18%) |Generate time=10.10s (44.29%) |Training time=7.32s (32.08%) |Others=5.39 (23.63%)|CurSamplesPerSec=11.22 |AvgSamplesPerSec=10.89
Epoch: 0 | Step: 4 | PPO Epoch: 1 | Actor Loss: -0.05925237387418747 | Critic Loss: 0.37406009435653687 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.84s, TFLOPs: 43.09, Samples/sec: 11.21, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.74s, Per-token Latency 57.58 ms, TFLOPs: 7.42, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.10s, TFLOPs: 108.00
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.153076171875
-------------------------------------------------------------------------------------
|E2E latency=22.85s |Gather latency=0.95s (4.17%) |Generate time=10.03s (43.92%) |Training time=7.36s (32.20%) |Others=5.45 (23.87%)|CurSamplesPerSec=11.21 |AvgSamplesPerSec=10.95
Epoch: 0 | Step: 5 | PPO Epoch: 1 | Actor Loss: 0.04100264608860016 | Critic Loss: 0.3846338987350464 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.64s, TFLOPs: 43.48, Samples/sec: 11.31, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.58s, Per-token Latency 56.96 ms, TFLOPs: 7.50, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.06s, TFLOPs: 108.59
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.10394287109375
-------------------------------------------------------------------------------------
|E2E latency=22.64s |Gather latency=0.94s (4.15%) |Generate time=10.05s (44.37%) |Training time=7.20s (31.82%) |Others=5.39 (23.81%)|CurSamplesPerSec=11.31 |AvgSamplesPerSec=11.01
Epoch: 0 | Step: 6 | PPO Epoch: 1 | Actor Loss: -0.025508785620331764 | Critic Loss: 0.5158730745315552 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.63s, TFLOPs: 43.50, Samples/sec: 11.31, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.57s, Per-token Latency 56.93 ms, TFLOPs: 7.50, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.06s, TFLOPs: 108.60
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.165283203125
-------------------------------------------------------------------------------------
|E2E latency=22.63s |Gather latency=0.91s (4.03%) |Generate time=10.04s (44.36%) |Training time=7.21s (31.87%) |Others=5.38 (23.77%)|CurSamplesPerSec=11.31 |AvgSamplesPerSec=11.05
Epoch: 0 | Step: 7 | PPO Epoch: 1 | Actor Loss: -0.1402130126953125 | Critic Loss: 0.3923710584640503 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.86s, TFLOPs: 43.05, Samples/sec: 11.20, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.83s, Per-token Latency 57.93 ms, TFLOPs: 7.37, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.03s, TFLOPs: 108.91
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.0733642578125
-------------------------------------------------------------------------------------
|E2E latency=22.87s |Gather latency=0.97s (4.25%) |Generate time=10.09s (44.11%) |Training time=7.35s (32.15%) |Others=5.43 (23.74%)|CurSamplesPerSec=11.19 |AvgSamplesPerSec=11.07
Epoch: 0 | Step: 8 | PPO Epoch: 1 | Actor Loss: 0.00875104684382677 | Critic Loss: 0.35604292154312134 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.84s, TFLOPs: 43.10, Samples/sec: 11.21, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.77s, Per-token Latency 57.71 ms, TFLOPs: 7.40, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.06s, TFLOPs: 108.49
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.11590576171875
-------------------------------------------------------------------------------------
|E2E latency=22.84s |Gather latency=0.97s (4.23%) |Generate time=10.05s (44.01%) |Training time=7.37s (32.27%) |Others=5.42 (23.73%)|CurSamplesPerSec=11.21 |AvgSamplesPerSec=11.08
[2024-04-28 09:56:16,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.65e-07, 9.65e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-04-28 09:56:16,914] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=62.867376008306344, CurrSamplesPerSec=61.703839085506225, MemAllocated=13.48GB, MaxMemAllocated=25.53GB
[2024-04-28 09:56:20,954] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[5.000000000000001e-07, 5.000000000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
Epoch: 0 | Step: 9 | PPO Epoch: 1 | Actor Loss: -0.018987394869327545 | Critic Loss: 0.380961537361145 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.86s, TFLOPs: 43.05, Samples/sec: 11.20, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.66s, Per-token Latency 57.26 ms, TFLOPs: 7.46, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.20s, TFLOPs: 106.63
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.130126953125
-------------------------------------------------------------------------------------
|E2E latency=22.87s |Gather latency=0.93s (4.07%) |Generate time=10.09s (44.11%) |Training time=7.33s (32.07%) |Others=5.45 (23.83%)|CurSamplesPerSec=11.20 |AvgSamplesPerSec=11.10
Epoch: 0 | Step: 10 | PPO Epoch: 1 | Actor Loss: -0.02388773486018181 | Critic Loss: 0.3241499662399292 | Unsupervised Loss: 0.0
End-to-End => Latency: 22.72s, TFLOPs: 43.33, Samples/sec: 11.27, Time/seq 0.09s, Batch Size: 256, Total Seq. Length: 512
Generation => Latency: 14.64s, Per-token Latency 57.20 ms, TFLOPs: 7.47, BW: -1.00 GB/sec, Answer Seq. Length: 256
Training   => Latency: 8.07s, TFLOPs: 108.38
Actor Model Parameters => 6.738 B, Critic Model Parameters => 6.607 B
Average reward score: 0.157958984375
-------------------------------------------------------------------------------------
exit with early finished, for debug
